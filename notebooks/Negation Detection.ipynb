{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import foodbornenyc.models.models as models\n",
    "from foodbornenyc.models.businesses import Business, business_category_table\n",
    "from foodbornenyc.models.documents import YelpReview, Tweet, Document\n",
    "from foodbornenyc.models.locations import Location\n",
    "from foodbornenyc.models.metadata import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "f = xlrd.open_workbook('data/yelp_sick_classifier_data.xlsx')\n",
    "sheet1 = f.sheet_by_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.95, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "        ...alty='l2', random_state=57, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "from foodbornenyc.settings import yelp_classify_config as config\n",
    "\n",
    "sick = joblib.load(\"../\"+config['model_file'])\n",
    "sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def analyze(reviews, classifier):\n",
    "    textonly = [a[\"text\"] for a in reviews]\n",
    "    predictions_new = classifier.predict_proba(textonly)\n",
    "    label = np.array([review['label'] for review in reviews])\n",
    "    pred = np.array([pred[1] for pred in predictions_new])\n",
    "    print \"ROC_AUC SCORE ::\", roc_auc_score(label, pred, average='micro')\n",
    "    # determine true/false positive/negative rates\n",
    "    tp_rate = 0.0\n",
    "    fp_rate = 0.0\n",
    "    tn_rate = 0.0\n",
    "    fn_rate = 0.0\n",
    "\n",
    "    for review, pred in zip(reviews, predictions_new):\n",
    "        if review['label'] == 1.0 and pred[1] > 0.5: tp_rate += 1\n",
    "        elif review['label'] == 1.0 and pred[1] < 0.5: fn_rate += 1\n",
    "        elif review['label'] == 0.0 and pred[1] > 0.5: fp_rate += 1\n",
    "        elif review['label'] == 0.0 and pred[1] < 0.5: tn_rate += 1\n",
    "    tp_rate /= len(reviews)\n",
    "    fn_rate /= len(reviews)\n",
    "    fp_rate /= len(reviews)\n",
    "    tn_rate /= len(reviews)\n",
    "    print \"True positive ::\", tp_rate\n",
    "    print \"False negative ::\", fn_rate\n",
    "    print \"False positive ::\", fp_rate\n",
    "    print \"True negative ::\", tn_rate\n",
    "    print \"FP / TP ::\", fp_rate / tp_rate\n",
    "    print \"FN / TN ::\", fn_rate / tn_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for i, (rev, label) in enumerate(zip(sheet1.col(1), sheet1.col(2))):\n",
    "    if i == 0: continue\n",
    "    reviews.append({\"text\":rev.value, \"label\":label.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.996294837238\n",
      "True positive :: 0.523706896552\n",
      "False negative :: 0.00933908045977\n",
      "False positive :: 0.00646551724138\n",
      "True negative :: 0.460488505747\n",
      "FP / TP :: 0.0123456790123\n",
      "FN / TN :: 0.0202808112324\n"
     ]
    }
   ],
   "source": [
    "analyze(reviews, sick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sheet2 = xlrd.open_workbook('data/sick_test_preds.xlsx').sheet_by_index(0)\n",
    "reviews2 = []\n",
    "for i, (rev, label) in enumerate(zip(sheet2.col(0), sheet2.col(3))):\n",
    "    if i == 0: continue\n",
    "    reviews2.append({\"text\":rev.value, \"label\":label.value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.999638616417\n",
      "True positive :: 0.530465949821\n",
      "False negative :: 0.00358422939068\n",
      "False positive :: 0.0143369175627\n",
      "True negative :: 0.451612903226\n",
      "FP / TP :: 0.027027027027\n",
      "FN / TN :: 0.00793650793651\n"
     ]
    }
   ],
   "source": [
    "analyze(reviews2, sick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('count',\n",
       "  CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=0.95, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)),\n",
       " ('tfidf',\n",
       "  TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       " ('log',\n",
       "  LogisticRegression(C=100, class_weight=None, dual=True, fit_intercept=True,\n",
       "            intercept_scaling=0.01, max_iter=100, multi_class='ovr',\n",
       "            n_jobs=1, penalty='l2', random_state=57, solver='liblinear',\n",
       "            tol=0.0001, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sick.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I nsubj hope  []\n",
      "hope ROOT hope  [u'I', u'gets', u'.']\n",
      "none nsubj gets  [u'of']\n",
      "of prep none  [u'us']\n",
      "us pobj of  []\n",
      "gets ccomp hope  [u'none', u'sick', u'tonight']\n",
      "sick acomp gets  []\n",
      "tonight npadvmod gets  []\n",
      ". punct hope  []\n",
      "I nsubj order  []\n",
      "did aux order  []\n",
      "n't neg order  []\n",
      "order ROOT order  [u'I', u'did', u\"n't\", u'poisoning', u'.']\n",
      "food compound poisoning []\n",
      "poisoning dobj order  [u'food']\n",
      ". punct order  []\n",
      "I nsubj think  []\n",
      "do aux think  []\n",
      "not neg think  []\n",
      "think ROOT think  [u'I', u'do', u'not', u'come', u'.']\n",
      "you nsubj come  []\n",
      "should aux come  []\n",
      "come ccomp think  [u'you', u'should', u'here', u'got']\n",
      "here advmod come  []\n",
      "because mark got  []\n",
      "I nsubj got  []\n",
      "got advcl come  [u'because', u'I', u'poisoning']\n",
      "food compound poisoning []\n",
      "poisoning dobj got  [u'food']\n",
      ". punct think  []\n"
     ]
    }
   ],
   "source": [
    "# key words to watch out for: poisoning, sick, \n",
    "# tokens that perform strictly negation: not, n't, no, none, nobody, neither, \n",
    "# if negation word's head == key word's head, prepend key word with \"not\" and remove negation word\n",
    "# only potential issue is double negative, e.g. \"no one didn't get food poisoning\", but this is a first step\n",
    "from spacy import attrs\n",
    "example = u\"I hope none of us gets sick tonight. I didn't order food poisoning. I do not think you should come here because I got food poisoning.\"\n",
    "parsedEx = parser(example)\n",
    "for token in parsedEx:\n",
    "    print token.orth_, token.dep_, token.head, [t.orth_ for t in token.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i hope none of us gets sick tonight . i did order food not poisoning . i do think you should come here because i got food not poisoning .\n"
     ]
    }
   ],
   "source": [
    "def transform_doc_1(doc): \n",
    "    #if root of sentence had negation and sentence contained kw\n",
    "    kw = ['poisoning', 'sick']\n",
    "    neg = ['not', \"n't\", 'no', 'none', 'nobody', 'neither']\n",
    "    parsedDoc = parser(doc.lower())\n",
    "    tokens = [[t.orth_ for t in s] for s in parsedDoc.sents] #this will be modified\n",
    "    sents = list(parsedDoc.sents)\n",
    "    for i in range(len(sents)):\n",
    "        # each span has only one root\n",
    "        if not any([c.orth_ in neg for c in sents[i].root.children]): continue #if there's no negation\n",
    "        neg_i = [j for j in range(len(sents[i])) if sents[i][j].orth_ in neg][0]\n",
    "        kw_list = [j for j in range(len(sents[i])) if sents[i][j].orth_ in kw]\n",
    "        \n",
    "        if len(kw_list) == 0: continue\n",
    "        \n",
    "        kw_i = kw_list[0]\n",
    "        \n",
    "        #now modify\n",
    "        tokens[i].insert(kw_i, \"not\")\n",
    "        tokens[i].pop(neg_i)\n",
    "    #now we join everything with spaces\n",
    "    out = []\n",
    "    for sent in tokens:\n",
    "        out.append(\" \".join(sent))\n",
    "    return \" \".join(out)\n",
    "\n",
    "print transform_doc_1(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i hope of us gets not sick tonight . i did order food not poisoning . i do not think you should come here because i got food poisoning .\n"
     ]
    }
   ],
   "source": [
    "def transform_doc_2(doc): \n",
    "    #if negation and kw share a head\n",
    "    kw = ['poisoning', 'sick']\n",
    "    neg = ['not', \"n't\", 'no', 'none', 'nobody', 'neither']\n",
    "    parsedDoc = parser(doc.lower())\n",
    "    tokens = [[t.orth_ for t in s] for s in parsedDoc.sents] #this will be modified\n",
    "    sents = list(parsedDoc.sents)\n",
    "    for i in range(len(sents)):\n",
    "        if not any([c.orth_ in neg for c in sents[i]]): continue #if there's no negation\n",
    "        neg_list = [j for j in range(len(sents[i])) if sents[i][j].orth_ in neg]\n",
    "        kw_list = [j for j in range(len(sents[i])) if sents[i][j].orth_ in kw]\n",
    "        \n",
    "        if len(kw_list) == 0: continue\n",
    "        \n",
    "        # attempt at handling double negatives\n",
    "        double_negative = True\n",
    "        kw_i = -1\n",
    "        neg_i = -1\n",
    "        \n",
    "        for j in neg_list:\n",
    "            for k in kw_list:\n",
    "                if sents[i][j].head == sents[i][k].head and double_negative:\n",
    "                    neg_i = j\n",
    "                    kw_i = k\n",
    "                    double_negative = False\n",
    "                elif sents[i][j].head == sents[i][k].head and not double_negative:\n",
    "                    double_negative = True\n",
    "        \n",
    "        if double_negative: continue\n",
    "        \n",
    "        #now modify\n",
    "        tokens[i].insert(kw_i, \"not\")\n",
    "        tokens[i].pop(neg_i)\n",
    "    #now we join everything with spaces\n",
    "    out = []\n",
    "    for sent in tokens:\n",
    "        out.append(\" \".join(sent))\n",
    "    return \" \".join(out)\n",
    "\n",
    "print transform_doc_2(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "class NegationTransformer(TransformerMixin):\n",
    "    \"\"\" Brings negation words closer to relevant key terms to make it detectable with n-gram detector \"\"\"\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return np.array([transform_doc_2(doc) for doc in X])\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('negTransformer', <__main__.NegationTransformer object at 0x1a0eac890>), ('oldPipe', Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.95,...y='l2', random_state=57, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('negTransformer', NegationTransformer()), ('oldPipe', sick)])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.996213974705\n",
      "True positive :: 0.524425287356\n",
      "False negative :: 0.00862068965517\n",
      "False positive :: 0.00718390804598\n",
      "True negative :: 0.459770114943\n",
      "FP / TP :: 0.013698630137\n",
      "FN / TN :: 0.01875\n",
      "CPU times: user 22.3 s, sys: 342 ms, total: 22.6 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%time analyze(reviews, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.999638616417\n",
      "True positive :: 0.530465949821\n",
      "False negative :: 0.00358422939068\n",
      "False positive :: 0.0179211469534\n",
      "True negative :: 0.448028673835\n",
      "FP / TP :: 0.0337837837838\n",
      "FN / TN :: 0.008\n",
      "CPU times: user 4.27 s, sys: 70.6 ms, total: 4.34 s\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%time analyze(reviews2, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try refitting the pipeline?\n",
    "pipe1 = Pipeline([('negTransformer', NegationTransformer()), ('oldPipe', sick)])\n",
    "pipe2 = Pipeline([('negTransformer', NegationTransformer()), ('oldPipe', sick)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fitting against reviews from scratch\n",
    "from sklearn import cross_validation\n",
    "data = {}\n",
    "data['X'] = [review['text'] for review in reviews]\n",
    "data['y'] = [review['label'] for review in reviews]\n",
    "folds = cross_validation.StratifiedKFold(data['y'], n_folds=3, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from yelp classifier training notebook\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "def my_roc_auc(ground_truth, predictions):\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    predictions = np.array(predictions)\n",
    "    return metrics.roc_auc_score(ground_truth, predictions, average='micro')\n",
    "\n",
    "my_roc_auc_scorer = metrics.make_scorer(my_roc_auc, needs_threshold=True, greater_is_better=True)\n",
    "# Feature Extractors\n",
    "cv = CountVectorizer(\n",
    "        input=u'content', \n",
    "        encoding=u'utf-8', \n",
    "        decode_error=u'strict', \n",
    "        strip_accents='unicode', \n",
    "        lowercase=True,\n",
    "        analyzer=u'word', \n",
    "        preprocessor=None, \n",
    "        tokenizer=None, \n",
    "        stop_words='english', \n",
    "        #token_pattern=u'(?u)\\\\b\\w\\w+\\b', # one alphanumeric is a token\n",
    "        ngram_range=(1, 2), \n",
    "        max_df=.9, \n",
    "        min_df=2, \n",
    "        max_features=None, \n",
    "        vocabulary=None, \n",
    "        binary=False, \n",
    "        #dtype=type 'numpy.int64'>\n",
    "        )\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf = TfidfTransformer(\n",
    "        norm='l2',\n",
    "        use_idf=True,\n",
    "        smooth_idf=True,\n",
    "        sublinear_tf=False\n",
    ")\n",
    "\n",
    "# Final Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "lr = LogisticRegression(C=.05,\n",
    "                        fit_intercept=True,\n",
    "                        random_state=0,\n",
    "                        class_weight='balanced',\n",
    "                        n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('negtransform', NegationTransformer()),\n",
    "    ('count', cv),\n",
    "    ('tfidf', tf),\n",
    "    ('logreg', lr)\n",
    "    ])\n",
    "\n",
    "param_grid = {\n",
    "    'count__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "    'tfidf__norm':['l1', 'l2'],\n",
    "    'tfidf__use_idf':[True, False],\n",
    "    'tfidf__sublinear_tf':[True,False],\n",
    "    'logreg__C':[.001, .01, .1]\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, \n",
    "                           param_grid,\n",
    "                           cv = folds,\n",
    "                           scoring=my_roc_auc_scorer,\n",
    "                           n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed: 32.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54 s, sys: 2.64 s, total: 56.7 s\n",
      "Wall time: 32min 24s\n",
      "()\n",
      "Best score: 0.874\n",
      "Best parameters set:\n",
      "\tcount__ngram_range: (1, 3)\n",
      "\tlogreg__C: 0.1\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__sublinear_tf: True\n",
      "\ttfidf__use_idf: True\n"
     ]
    }
   ],
   "source": [
    "%time grid_search.fit(np.array(data['X']), data['y'])\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.960976570599\n",
      "True positive :: 0.450431034483\n",
      "False negative :: 0.0826149425287\n",
      "False positive :: 0.0359195402299\n",
      "True negative :: 0.431034482759\n",
      "FP / TP :: 0.0797448165869\n",
      "FN / TN :: 0.191666666667\n",
      "CPU times: user 20.6 s, sys: 210 ms, total: 20.8 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%time analyze(reviews, grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.956530717605\n",
      "True positive :: 0.462365591398\n",
      "False negative :: 0.0716845878136\n",
      "False positive :: 0.0465949820789\n",
      "True negative :: 0.41935483871\n",
      "FP / TP :: 0.100775193798\n",
      "FN / TN :: 0.17094017094\n",
      "CPU times: user 4.22 s, sys: 41.7 ms, total: 4.26 s\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%time analyze(reviews2, grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.533701446553\n",
      "After posting my original review, the NYC Health Dept contacted me and urged me to call 311 to report the food poisoning incident at Atlas Cafe.  I would like to clarify I did not contract food poisoning from Atlas Cafe.  I merely likened the urgency to post my one star review of Atlas to my urgency to use the bathroom when I did contract food poisoning from a wedding in Jersey.\n",
      "\n",
      "0.51326629088\n",
      "After reading all the rave reviews about Schnitzi, I finally decided to try it out. What a mistake!!!\n",
      "The place is filthy, the menu prices are too high and the food sucks. I tried their double burger. They barely put tomatoes or pickles in my sandwich. The sauce wasn&#39;t that great, but the worst part was the meat. The burgers were two pieces of rubber that tasted horrible.\n",
      "All night I was burping nasty burps that felt like I ate a whole rotten cow. The next day I was still sick from this crappy burger and all my clothes smelled of filthy food.\n",
      "I don&#39;t recommend this place to anyone.\n",
      "\n",
      "0.511663871372\n",
      "After waiting 2 hours for a table, I think my expectations were too high for this place. \n",
      "\n",
      "I would give it 4 stars but my friend and I had really bad indigestion or some stomach problems right after eating the butter drench, garlic food.\n",
      "\n",
      "We got the Shrimp and Crawfish combo, snowcrab and the lobster and crawfish.. the lobster combo was $40 because it&#39;s &#34;marketprice&#34; but why wouldn&#39;t they just have that on the menu?\n",
      "\n",
      "The shrimp and the snowcrabs were my favorite the cajun wings were really juicy and flavorful. I really like garlic (not powder, salt, seasoning) raw garlic and the boil uses LOTS of it.\n",
      "\n",
      "After  20 minutes into eating, I felt sick and the food was too greasy with butter so I asked for rice, which the server got the saddest side of rice which didn&#39;t even look like a bowl of rice but a square of rice... I didn&#39;t even know rice could all mesh together like mash potato and be shaped that way. On top of that I was charged $3 for it.\n",
      "\n",
      "\n",
      "\n",
      "cash only. ugh.\n",
      "\n",
      "0.525498044881\n",
      "Good summer time bar stop.  They have a rooftop which is pretty cool.  There is a good selection of beers as well.  I've been here half a dozen times and always enjoyed the experience.\n",
      "\n",
      "Only reason I'm not gonna give this 5 stars is I got food poisoning the last time I was there after ordering a turkey burger.  I didn't eat anything else that day and it took days to pass.\n",
      "\n",
      "0.554579195977\n",
      "Got sick after eating their food truck burger.\n",
      "\n",
      "Stay away!\n",
      "\n",
      "0.503450779576\n",
      "I recently went to an event at Barclays with some friends and walked out starving.  Most of the Park Slope restaurants are closed by 11:30.  I&#39;d been to 200 5th a few years ago and it was solid.  Good beer selection, solid bar food.  \n",
      "\n",
      "The recent experience was nothing like the past ones.  First round of beers comes, one is skunked.  It happens, I think nothing of it.  Waitress is totally cool with letting a change happen.  Different beer comes, it&#39;s skunked again!  \n",
      "\n",
      "Honey wings, very good.  Since I can&#39;t give this experience 0 stars, the honey wings are reason for a star.  \n",
      "\n",
      "The entrees ordered should have been layups.  Burger, turkey burger and grilled cheese.  It&#39;s not like we ordered the fish and chicken cordon bleu.  I ate the burger because I&#39;m a dude and I was starving, but I was praying for no food poisoning when I got home.  The meat tasted old.  The bun was dry and tasteless.  It was so horrible that I removed the burger/cheese/veggies and ate it separately.  I should have sent everything back but at this point it would have been a pointless exercise.  I just needed to get out of there.\n",
      "\n",
      "The curly fries were average, not bad.  Friend got onion rings on the side, decent also.   \n",
      "\n",
      "I&#39;m disappointed by experience here.  It&#39;s a great setup for a game.  I&#39;d say if you are going here get the wings and beer on bottle to keep it simple and safe.\n",
      "\n",
      "0.525922005248\n",
      "I would give zero if I could. This is the worst Restaurant I have ever been at! \n",
      "\n",
      "We only went in to that Taco bell because it was 96 degrees outside and we wanted to get some cool Air. The place we originally wanted to stay at had no AC and basically yelled food poisoning but would have been the better choice.\n",
      "\n",
      "So, let&#39;s start with the completely depressing, run down look. We where the only customers  on a Saturday afternoon. Most of the tables where really dirty and the chairs had ripped and worn off. \n",
      "\n",
      "When I ordered my food, the casher was completely unable to use the register. It took him like 10 minutes to take my order, he got it wrong and charged me more than it was, since he was unable to figure our the lunch-box thing... He then forgot my cup and after I asked for it, he gave me neither a straw nor a lid. \n",
      "\n",
      "i ate half of the food that he gave me, then threw it away since i was to afraid to get food poisoning and it tasted like nothing. \n",
      "\n",
      "I was so glad to get out of there and swore to myself: never again!\n",
      "\n",
      "0.507638789559\n",
      "It&#39;s decent cheap American-Chinese food.  I don&#39;t understand the negative reviews.  Also they have an A health code rating, which 2 of the local competitors do not.  At least I know I&#39;m not going to get sick after eating here.  They are very nice people too.\n",
      "\n",
      "0.514535465408\n",
      "Ordered delivery for the first and last time tonight. The estimate delivery time they gave me was 37 minutes, after one hour of waiting I called and the man on the phone told me it had just left... No apologizes for the delay or anything. 30 minutes later I finally got the food, that took a total of an hour and a half to get here. \n",
      "\n",
      "The falafel and dynamite sandwich we ordered tasted like they had been sitting in the delivery bike for way too long. Falafel was cold and dry, the pita wrap was soggy...\n",
      "\n",
      "We also ordered hummus and baba ganoush which are hard to mess up. They both felt like they had just been taken out of a freezer, they were chunky and very cold. The baba ganoush had a weird tone and smell to it so we didn&#39;t eat it, and the hummus had a weird chunky consistency and was half frozen as well. The pita bread that we ordered to go with it was equally bad. Dry, tasted like cardboard, I could have bought a better pita bread at the corner store. It&#39;s hard to mess up mediterranean food as long as you use fresh ingredients, but this place didn&#39;t do a single thing right. They also forgot our salad, but I didn&#39;t bother to call about it seeing the quality of their other food. \n",
      "\n",
      "Only pro is that I didn&#39;t get food poisoning.\n",
      "\n",
      "0.542518294141\n",
      "The worst Brazilian restaurant I&#39;ve ever eaten. My husband ordered a medium steak and I ordered a medium well.... We  both got well done, hard steaks that we couldn&#39;t finish. I got really sick of my stomach. I&#39;ll never go back, and won&#39;t recommend. BTW, I am Brazilian, I know my !@#$%^&amp;*\n",
      "\n",
      "0.508441381839\n",
      "Totally overrated, waited about an hour for a table. We had the mussels (bland and my friend said the freshness was questionable and as much as i love food poisoning, no thanks) the gnocchi (couldn&#39;t finish it, it had this odd bitter taste) and the flan (the best thing we had there and thats not really an italian dessert)You&#39;re also forced to listen to other guests conversations since they are basically sitting on your lap... However, prices are decent...\n",
      "\n",
      "0.503887383292\n",
      "Very bad food and service. \n",
      "We ordered chicken and pasta and the food came faster than in any fast food restaurant.\n",
      "The food itself was terrible and we didn't finish our plate as we were scared to be sick.\n",
      "The waiter was rude.\n",
      "It's a pity because the restaurant itself is very unique (decoration, live music).\n",
      "But i will not come back .\n",
      "\n",
      "0.500587385964\n",
      "We decided to try our hand making linguine and clams after getting sick of paying $20+ to get a subpar version at different restaurants. The main problem was finding clams fresh enough for the dish. The last time a friend picked up &#34;fresh&#34; fish at Whole Foods, he had food poisoning. Yelp reviews led us to Rosendo where we got a dozen little neck clams that were on ice. After washing and cooking, every clam popped open and proved to be fresh. \n",
      "\n",
      "The place was a little tough to find considering the unassuming storefront and the wrong yelp address. All I remember is that it&#39;s near a Kumon. Man, I hate Kumon haha.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def reveal_fp(reviews, classifier):\n",
    "    prediction = classifier.predict_proba([a['text'] for a in reviews])\n",
    "    for review, pred in zip(reviews, prediction):\n",
    "        if review['label'] == 0.0 and pred[1] > 0.5:\n",
    "            print pred[1]\n",
    "            print review['text']\n",
    "            print\n",
    "\n",
    "reveal_fp(reviews2, grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.95, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "        ...alty='l2', random_state=57, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2 = GridSearchCV(sick, \n",
    "                           param_grid,\n",
    "                           cv = folds,\n",
    "                           scoring=my_roc_auc_scorer,\n",
    "                           n_jobs=-1, verbose=1)\n",
    "sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x1028ef4b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/kevin...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x1028ef4b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/kevin...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    384     def start(self):\n    385         if self.poller is not None:\n    386             self.poller.start()\n    387         self.kernel.start()\n    388         try:\n--> 389             ioloop.IOLoop.instance().start()\n    390         except KeyboardInterrupt:\n    391             pass\n    392 \n    393 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    861                 self._events.update(event_pairs)\n    862                 while self._events:\n    863                     fd, events = self._events.popitem()\n    864                     try:\n    865                         fd_obj, handler_func = self._handlers[fd]\n--> 866                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    867                     except (OSError, IOError) as e:\n    868                         if errno_from_exception(e) == errno.EPIPE:\n    869                             # Happens when the client closes the connection\n    870                             pass\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    247         if self.control_stream:\n    248             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    249 \n    250         def make_dispatcher(stream):\n    251             def dispatcher(msg):\n--> 252                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    253             return dispatcher\n    254 \n    255         for s in self.shell_streams:\n    256             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}})\n    208         else:\n    209             # ensure default_int_handler during handler call\n    210             sig = signal(SIGINT, default_int_handler)\n    211             self.log.debug(\"%s: %s\", msg_type, msg)\n    212             try:\n--> 213                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['15B18E86CB1040EAB3CDC14267BDB3E4']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}}\n    214             except Exception:\n    215                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    216             finally:\n    217                 signal(SIGINT, sig)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['15B18E86CB1040EAB3CDC14267BDB3E4'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}})\n    357         if not silent:\n    358             self.execution_count += 1\n    359             self._publish_execute_input(code, parent, self.execution_count)\n    360 \n    361         reply_content = self.do_execute(code, silent, store_history,\n--> 362                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    363 \n    364         # Flush output before sending the reply.\n    365         sys.stdout.flush()\n    366         sys.stderr.flush()\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-62-d7cb5029435f>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3001 \n   3002         try:\n   3003             for i, node in enumerate(to_run_exec):\n   3004                 mod = ast.Module([node])\n   3005                 code = compiler(mod, cell_name, \"exec\")\n-> 3006                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>\n        self.user_global_ns = {'Business': <class 'foodbornenyc.models.businesses.Business'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Document': <class 'foodbornenyc.models.documents.Document'>, 'English': <class 'spacy.en.English'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"#from yelp classifier training notebook\\nfrom ...                           n_jobs=-1, verbose=1)\", u'from spacy.en import English\\nparser = English()', u'import foodbornenyc.models.models as models\\nf...rom foodbornenyc.models.metadata import metadata', u\"import xlrd\\nf = xlrd.open_workbook('data/yelp...sifier_data.xlsx')\\nsheet1 = f.sheet_by_index(0)\", u'from sklearn.externals import joblib\\nfrom foo... joblib.load(\"../\"+config[\\'model_file\\'])\\nsick', u'import numpy as np\\nfrom sklearn.metrics impor...t fp_rate / tp_rate\\n    print fn_rate / tn_rate', u'reviews = []\\nfor i, (rev, label) in enumerate...:rev.value, \"label\":label.value})\\nprint reviews', u'analyze(reviews, sick)', u'sheet2 = xlrd.open_workbook(\\'data/sick_test_p...rev.value, \"label\":label.value})\\nprint reviews2', u'analyze(reviews2, sick)', u'sick.steps', u'# key words to watch out for: poisoning, sick,..._, token.head, [t.orth_ for t in token.children]', u'def transform_doc_1(doc): \\n    #if root of se... \" \".join(out)\\n\\nprint transform_doc_1(example)', u'def transform_doc_2(doc): \\n    #if negation a... \" \".join(out)\\n\\nprint transform_doc_2(example)', u'from sklearn.base import TransformerMixin\\ncla...=None, **fit_params):\\n        return self\\n    ', u\"from sklearn.pipeline import Pipeline\\npipe = ...egationTransformer()), ('oldPipe', sick)])\\npipe\", u'analyze(reviews, pipe)', u'analyze(reviews2, pipe)', u\"#try refitting the pipeline?\\npipe1 = Pipeline...er', NegationTransformer()), ('oldPipe', sick)])\", ...], 'Location': <class 'foodbornenyc.models.locations.Location'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NegationTransformer': <class '__main__.NegationTransformer'>, ...}\n        self.user_ns = {'Business': <class 'foodbornenyc.models.businesses.Business'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Document': <class 'foodbornenyc.models.documents.Document'>, 'English': <class 'spacy.en.English'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"#from yelp classifier training notebook\\nfrom ...                           n_jobs=-1, verbose=1)\", u'from spacy.en import English\\nparser = English()', u'import foodbornenyc.models.models as models\\nf...rom foodbornenyc.models.metadata import metadata', u\"import xlrd\\nf = xlrd.open_workbook('data/yelp...sifier_data.xlsx')\\nsheet1 = f.sheet_by_index(0)\", u'from sklearn.externals import joblib\\nfrom foo... joblib.load(\"../\"+config[\\'model_file\\'])\\nsick', u'import numpy as np\\nfrom sklearn.metrics impor...t fp_rate / tp_rate\\n    print fn_rate / tn_rate', u'reviews = []\\nfor i, (rev, label) in enumerate...:rev.value, \"label\":label.value})\\nprint reviews', u'analyze(reviews, sick)', u'sheet2 = xlrd.open_workbook(\\'data/sick_test_p...rev.value, \"label\":label.value})\\nprint reviews2', u'analyze(reviews2, sick)', u'sick.steps', u'# key words to watch out for: poisoning, sick,..._, token.head, [t.orth_ for t in token.children]', u'def transform_doc_1(doc): \\n    #if root of se... \" \".join(out)\\n\\nprint transform_doc_1(example)', u'def transform_doc_2(doc): \\n    #if negation a... \" \".join(out)\\n\\nprint transform_doc_2(example)', u'from sklearn.base import TransformerMixin\\ncla...=None, **fit_params):\\n        return self\\n    ', u\"from sklearn.pipeline import Pipeline\\npipe = ...egationTransformer()), ('oldPipe', sick)])\\npipe\", u'analyze(reviews, pipe)', u'analyze(reviews2, pipe)', u\"#try refitting the pipeline?\\npipe1 = Pipeline...er', NegationTransformer()), ('oldPipe', sick)])\", ...], 'Location': <class 'foodbornenyc.models.locations.Location'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NegationTransformer': <class '__main__.NegationTransformer'>, ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/Users/kevinzeng/FoodborneNYC/notebooks/<ipython-input-62-d7cb5029435f> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 grid_search2.fit(np.array(data['X']), data['y'])\n      7 print()\n      8 \n      9 print(\"Best score: %0.3f\" % grid_search2.best_score_)\n     10 print(\"Best parameters set:\")\n     11 best_parameters2 = grid_search2.best_estimator_.get_params()\n     12 for param_name in sorted(param_grid.keys()):\n     13     print(\"\\t%s: %r\" % (param_name, best_parameters2[param_name]))\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...rer(my_roc_auc, needs_threshold=True), verbose=1), X=array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...])\n    799         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    800             Target relative to X for classification or regression;\n    801             None for unsupervised learning.\n    802 \n    803         \"\"\"\n--> 804         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...er(my_roc_auc, needs_threshold=True), verbose=1)>\n        X = array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952')\n        y = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]\n        self.param_grid = {'count__ngram_range': [(1, 1), (1, 2), (1, 3)], 'logreg__C': [0.001, 0.01, 0.1], 'tfidf__norm': ['l1', 'l2'], 'tfidf__sublinear_tf': [True, False], 'tfidf__use_idf': [True, False]}\n    805 \n    806 \n    807 class RandomizedSearchCV(BaseSearchCV):\n    808     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...rer(my_roc_auc, needs_threshold=True), verbose=1), X=array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    548         )(\n    549             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    550                                     train, test, self.verbose, parameters,\n    551                                     self.fit_params, return_parameters=True,\n    552                                     error_score=self.error_score)\n--> 553                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    554                 for train, test in cv)\n    555 \n    556         # Out is a list of triplet: score, estimator, n_test_samples\n    557         n_fits = len(out)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu May  5 21:20:01 2016\nPID: 49031     Python 2.7.9: /Users/kevinzeng/.virtualenvs/fbnyc/bin/python\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], make_scorer(my_roc_auc, needs_threshold=True), array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), 1, {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], make_scorer(my_roc_auc, needs_threshold=True), array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), 1, {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), X=memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], scorer=make_scorer(my_roc_auc, needs_threshold=True), train=array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), test=array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), verbose=1, parameters={'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1515     fit_params = fit_params if fit_params is not None else {}\n   1516     fit_params = dict([(k, _index_param_value(X, v, train))\n   1517                       for k, v in fit_params.items()])\n   1518 \n   1519     if parameters is not None:\n-> 1520         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...     tol=0.0001, verbose=0, warm_start=False))])>\n        parameters = {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n   1521 \n   1522     start_time = time.time()\n   1523 \n   1524     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), **params={'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True})\n    256                 name, sub_name = split\n    257                 if name not in valid_params:\n    258                     raise ValueError('Invalid parameter %s for estimator %s. '\n    259                                      'Check the list of available parameters '\n    260                                      'with `estimator.get_params().keys()`.' %\n--> 261                                      (name, self))\n        name = 'logreg'\n        self = Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))])\n    262                 sub_object = valid_params[name]\n    263                 sub_object.set_params(**{sub_name: value})\n    264             else:\n    265                 # simple objects case\n\nValueError: Invalid parameter logreg for estimator Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n        lowercase=True, max_df=0.95, max_features=None, min_df=1,\n        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n        ...alty='l2', random_state=57, solver='liblinear',\n          tol=0.0001, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-d7cb5029435f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgrid_search2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0;31m# a working pool as they expect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x1028ef4b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/kevin...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x1028ef4b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/kevin...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    384     def start(self):\n    385         if self.poller is not None:\n    386             self.poller.start()\n    387         self.kernel.start()\n    388         try:\n--> 389             ioloop.IOLoop.instance().start()\n    390         except KeyboardInterrupt:\n    391             pass\n    392 \n    393 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    861                 self._events.update(event_pairs)\n    862                 while self._events:\n    863                     fd, events = self._events.popitem()\n    864                     try:\n    865                         fd_obj, handler_func = self._handlers[fd]\n--> 866                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    867                     except (OSError, IOError) as e:\n    868                         if errno_from_exception(e) == errno.EPIPE:\n    869                             # Happens when the client closes the connection\n    870                             pass\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    247         if self.control_stream:\n    248             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    249 \n    250         def make_dispatcher(stream):\n    251             def dispatcher(msg):\n--> 252                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    253             return dispatcher\n    254 \n    255         for s in self.shell_streams:\n    256             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}})\n    208         else:\n    209             # ensure default_int_handler during handler call\n    210             sig = signal(SIGINT, default_int_handler)\n    211             self.log.debug(\"%s: %s\", msg_type, msg)\n    212             try:\n--> 213                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['15B18E86CB1040EAB3CDC14267BDB3E4']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}}\n    214             except Exception:\n    215                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    216             finally:\n    217                 signal(SIGINT, sig)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['15B18E86CB1040EAB3CDC14267BDB3E4'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}})\n    357         if not silent:\n    358             self.execution_count += 1\n    359             self._publish_execute_input(code, parent, self.execution_count)\n    360 \n    361         reply_content = self.do_execute(code, silent, store_history,\n--> 362                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    363 \n    364         # Flush output before sending the reply.\n    365         sys.stdout.flush()\n    366         sys.stderr.flush()\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-62-d7cb5029435f>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3001 \n   3002         try:\n   3003             for i, node in enumerate(to_run_exec):\n   3004                 mod = ast.Module([node])\n   3005                 code = compiler(mod, cell_name, \"exec\")\n-> 3006                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>\n        self.user_global_ns = {'Business': <class 'foodbornenyc.models.businesses.Business'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Document': <class 'foodbornenyc.models.documents.Document'>, 'English': <class 'spacy.en.English'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"#from yelp classifier training notebook\\nfrom ...                           n_jobs=-1, verbose=1)\", u'from spacy.en import English\\nparser = English()', u'import foodbornenyc.models.models as models\\nf...rom foodbornenyc.models.metadata import metadata', u\"import xlrd\\nf = xlrd.open_workbook('data/yelp...sifier_data.xlsx')\\nsheet1 = f.sheet_by_index(0)\", u'from sklearn.externals import joblib\\nfrom foo... joblib.load(\"../\"+config[\\'model_file\\'])\\nsick', u'import numpy as np\\nfrom sklearn.metrics impor...t fp_rate / tp_rate\\n    print fn_rate / tn_rate', u'reviews = []\\nfor i, (rev, label) in enumerate...:rev.value, \"label\":label.value})\\nprint reviews', u'analyze(reviews, sick)', u'sheet2 = xlrd.open_workbook(\\'data/sick_test_p...rev.value, \"label\":label.value})\\nprint reviews2', u'analyze(reviews2, sick)', u'sick.steps', u'# key words to watch out for: poisoning, sick,..._, token.head, [t.orth_ for t in token.children]', u'def transform_doc_1(doc): \\n    #if root of se... \" \".join(out)\\n\\nprint transform_doc_1(example)', u'def transform_doc_2(doc): \\n    #if negation a... \" \".join(out)\\n\\nprint transform_doc_2(example)', u'from sklearn.base import TransformerMixin\\ncla...=None, **fit_params):\\n        return self\\n    ', u\"from sklearn.pipeline import Pipeline\\npipe = ...egationTransformer()), ('oldPipe', sick)])\\npipe\", u'analyze(reviews, pipe)', u'analyze(reviews2, pipe)', u\"#try refitting the pipeline?\\npipe1 = Pipeline...er', NegationTransformer()), ('oldPipe', sick)])\", ...], 'Location': <class 'foodbornenyc.models.locations.Location'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NegationTransformer': <class '__main__.NegationTransformer'>, ...}\n        self.user_ns = {'Business': <class 'foodbornenyc.models.businesses.Business'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Document': <class 'foodbornenyc.models.documents.Document'>, 'English': <class 'spacy.en.English'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"#from yelp classifier training notebook\\nfrom ...                           n_jobs=-1, verbose=1)\", u'from spacy.en import English\\nparser = English()', u'import foodbornenyc.models.models as models\\nf...rom foodbornenyc.models.metadata import metadata', u\"import xlrd\\nf = xlrd.open_workbook('data/yelp...sifier_data.xlsx')\\nsheet1 = f.sheet_by_index(0)\", u'from sklearn.externals import joblib\\nfrom foo... joblib.load(\"../\"+config[\\'model_file\\'])\\nsick', u'import numpy as np\\nfrom sklearn.metrics impor...t fp_rate / tp_rate\\n    print fn_rate / tn_rate', u'reviews = []\\nfor i, (rev, label) in enumerate...:rev.value, \"label\":label.value})\\nprint reviews', u'analyze(reviews, sick)', u'sheet2 = xlrd.open_workbook(\\'data/sick_test_p...rev.value, \"label\":label.value})\\nprint reviews2', u'analyze(reviews2, sick)', u'sick.steps', u'# key words to watch out for: poisoning, sick,..._, token.head, [t.orth_ for t in token.children]', u'def transform_doc_1(doc): \\n    #if root of se... \" \".join(out)\\n\\nprint transform_doc_1(example)', u'def transform_doc_2(doc): \\n    #if negation a... \" \".join(out)\\n\\nprint transform_doc_2(example)', u'from sklearn.base import TransformerMixin\\ncla...=None, **fit_params):\\n        return self\\n    ', u\"from sklearn.pipeline import Pipeline\\npipe = ...egationTransformer()), ('oldPipe', sick)])\\npipe\", u'analyze(reviews, pipe)', u'analyze(reviews2, pipe)', u\"#try refitting the pipeline?\\npipe1 = Pipeline...er', NegationTransformer()), ('oldPipe', sick)])\", ...], 'Location': <class 'foodbornenyc.models.locations.Location'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NegationTransformer': <class '__main__.NegationTransformer'>, ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/Users/kevinzeng/FoodborneNYC/notebooks/<ipython-input-62-d7cb5029435f> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 grid_search2.fit(np.array(data['X']), data['y'])\n      7 print()\n      8 \n      9 print(\"Best score: %0.3f\" % grid_search2.best_score_)\n     10 print(\"Best parameters set:\")\n     11 best_parameters2 = grid_search2.best_estimator_.get_params()\n     12 for param_name in sorted(param_grid.keys()):\n     13     print(\"\\t%s: %r\" % (param_name, best_parameters2[param_name]))\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...rer(my_roc_auc, needs_threshold=True), verbose=1), X=array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...])\n    799         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    800             Target relative to X for classification or regression;\n    801             None for unsupervised learning.\n    802 \n    803         \"\"\"\n--> 804         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...er(my_roc_auc, needs_threshold=True), verbose=1)>\n        X = array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952')\n        y = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]\n        self.param_grid = {'count__ngram_range': [(1, 1), (1, 2), (1, 3)], 'logreg__C': [0.001, 0.01, 0.1], 'tfidf__norm': ['l1', 'l2'], 'tfidf__sublinear_tf': [True, False], 'tfidf__use_idf': [True, False]}\n    805 \n    806 \n    807 class RandomizedSearchCV(BaseSearchCV):\n    808     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...rer(my_roc_auc, needs_threshold=True), verbose=1), X=array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    548         )(\n    549             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    550                                     train, test, self.verbose, parameters,\n    551                                     self.fit_params, return_parameters=True,\n    552                                     error_score=self.error_score)\n--> 553                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    554                 for train, test in cv)\n    555 \n    556         # Out is a list of triplet: score, estimator, n_test_samples\n    557         n_fits = len(out)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu May  5 21:20:01 2016\nPID: 49031     Python 2.7.9: /Users/kevinzeng/.virtualenvs/fbnyc/bin/python\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], make_scorer(my_roc_auc, needs_threshold=True), array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), 1, {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], make_scorer(my_roc_auc, needs_threshold=True), array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), 1, {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), X=memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], scorer=make_scorer(my_roc_auc, needs_threshold=True), train=array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), test=array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), verbose=1, parameters={'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1515     fit_params = fit_params if fit_params is not None else {}\n   1516     fit_params = dict([(k, _index_param_value(X, v, train))\n   1517                       for k, v in fit_params.items()])\n   1518 \n   1519     if parameters is not None:\n-> 1520         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...     tol=0.0001, verbose=0, warm_start=False))])>\n        parameters = {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n   1521 \n   1522     start_time = time.time()\n   1523 \n   1524     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), **params={'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True})\n    256                 name, sub_name = split\n    257                 if name not in valid_params:\n    258                     raise ValueError('Invalid parameter %s for estimator %s. '\n    259                                      'Check the list of available parameters '\n    260                                      'with `estimator.get_params().keys()`.' %\n--> 261                                      (name, self))\n        name = 'logreg'\n        self = Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))])\n    262                 sub_object = valid_params[name]\n    263                 sub_object.set_params(**{sub_name: value})\n    264             else:\n    265                 # simple objects case\n\nValueError: Invalid parameter logreg for estimator Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n        lowercase=True, max_df=0.95, max_features=None, min_df=1,\n        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n        ...alty='l2', random_state=57, solver='liblinear',\n          tol=0.0001, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "grid_search2.fit(np.array(data['X']), data['y'])\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search2.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters2 = grid_search2.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters2[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
