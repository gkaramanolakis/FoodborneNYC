{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import foodbornenyc.models.models as models\n",
    "from foodbornenyc.models.businesses import Business, business_category_table\n",
    "from foodbornenyc.models.documents import YelpReview, Tweet, Document\n",
    "from foodbornenyc.models.locations import Location\n",
    "from foodbornenyc.models.metadata import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "f = xlrd.open_workbook('data/yelp_sick_classifier_data.xlsx')\n",
    "sheet1 = f.sheet_by_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.95, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "        ...alty='l2', random_state=57, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "from foodbornenyc.settings import yelp_classify_config as config\n",
    "\n",
    "sick = joblib.load(\"../\"+config['model_file'])\n",
    "sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def analyze(reviews, classifier):\n",
    "    textonly = [a[\"text\"] for a in reviews]\n",
    "    predictions_new = classifier.predict_proba(textonly)\n",
    "    label = np.array([review['label'] for review in reviews])\n",
    "    pred = np.array([pred[1] for pred in predictions_new])\n",
    "    print \"ROC_AUC SCORE ::\", roc_auc_score(label, pred, average='micro')\n",
    "    # determine true/false positive/negative rates\n",
    "    tp_rate = 0.0\n",
    "    fp_rate = 0.0\n",
    "    tn_rate = 0.0\n",
    "    fn_rate = 0.0\n",
    "\n",
    "    for review, pred in zip(reviews, predictions_new):\n",
    "        if review['label'] == 1.0 and pred[1] > 0.5: tp_rate += 1\n",
    "        elif review['label'] == 1.0 and pred[1] < 0.5: fn_rate += 1\n",
    "        elif review['label'] == 0.0 and pred[1] > 0.5: fp_rate += 1\n",
    "        elif review['label'] == 0.0 and pred[1] < 0.5: tn_rate += 1\n",
    "    tp_rate /= len(reviews)\n",
    "    fn_rate /= len(reviews)\n",
    "    fp_rate /= len(reviews)\n",
    "    tn_rate /= len(reviews)\n",
    "    print \"True positive ::\", tp_rate\n",
    "    print \"False negative ::\", fn_rate\n",
    "    print \"False positive ::\", fp_rate\n",
    "    print \"True negative ::\", tn_rate\n",
    "    print \"FP / TP ::\", fp_rate / tp_rate\n",
    "    print \"FN / TN ::\", fn_rate / tn_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for i, (rev, label) in enumerate(zip(sheet1.col(1), sheet1.col(2))):\n",
    "    if i == 0: continue\n",
    "    reviews.append({\"text\":rev.value, \"label\":label.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.996294837238\n",
      "True positive :: 0.523706896552\n",
      "False negative :: 0.00933908045977\n",
      "False positive :: 0.00646551724138\n",
      "True negative :: 0.460488505747\n",
      "FP / TP :: 0.0123456790123\n",
      "FN / TN :: 0.0202808112324\n"
     ]
    }
   ],
   "source": [
    "analyze(reviews, sick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sheet2 = xlrd.open_workbook('data/sick_test_preds.xlsx').sheet_by_index(0)\n",
    "reviews2 = []\n",
    "for i, (rev, label) in enumerate(zip(sheet2.col(0), sheet2.col(3))):\n",
    "    if i == 0: continue\n",
    "    reviews2.append({\"text\":rev.value, \"label\":label.value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.999638616417\n",
      "True positive :: 0.530465949821\n",
      "False negative :: 0.00358422939068\n",
      "False positive :: 0.0143369175627\n",
      "True negative :: 0.451612903226\n",
      "FP / TP :: 0.027027027027\n",
      "FN / TN :: 0.00793650793651\n"
     ]
    }
   ],
   "source": [
    "analyze(reviews2, sick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('count',\n",
       "  CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=0.95, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)),\n",
       " ('tfidf',\n",
       "  TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       " ('log',\n",
       "  LogisticRegression(C=100, class_weight=None, dual=True, fit_intercept=True,\n",
       "            intercept_scaling=0.01, max_iter=100, multi_class='ovr',\n",
       "            n_jobs=1, penalty='l2', random_state=57, solver='liblinear',\n",
       "            tol=0.0001, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sick.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I nsubj hope  []\n",
      "hope ROOT hope  [u'I', u'gets', u'.']\n",
      "none nsubj gets  [u'of']\n",
      "of prep none  [u'us']\n",
      "us pobj of  []\n",
      "gets ccomp hope  [u'none', u'sick', u'tonight']\n",
      "sick acomp gets  []\n",
      "tonight npadvmod gets  []\n",
      ". punct hope  []\n",
      "I nsubj order  []\n",
      "did aux order  []\n",
      "n't neg order  []\n",
      "order ROOT order  [u'I', u'did', u\"n't\", u'poisoning', u'.']\n",
      "food compound poisoning []\n",
      "poisoning dobj order  [u'food']\n",
      ". punct order  []\n",
      "I nsubj think  []\n",
      "do aux think  []\n",
      "not neg think  []\n",
      "think ROOT think  [u'I', u'do', u'not', u'come', u'.']\n",
      "you nsubj come  []\n",
      "should aux come  []\n",
      "come ccomp think  [u'you', u'should', u'here', u'got']\n",
      "here advmod come  []\n",
      "because mark got  []\n",
      "I nsubj got  []\n",
      "got advcl come  [u'because', u'I', u'poisoning']\n",
      "food compound poisoning []\n",
      "poisoning dobj got  [u'food']\n",
      ". punct think  []\n"
     ]
    }
   ],
   "source": [
    "# key words to watch out for: poisoning, sick, \n",
    "# tokens that perform strictly negation: not, n't, no, none, nobody, neither, \n",
    "# if negation word's head == key word's head, prepend key word with \"not\" and remove negation word\n",
    "# only potential issue is double negative, e.g. \"no one didn't get food poisoning\", but this is a first step\n",
    "from spacy import attrs\n",
    "example = u\"I hope none of us gets sick tonight. I didn't order food poisoning. I do not think you should come here because I got food poisoning.\"\n",
    "parsedEx = parser(example)\n",
    "for token in parsedEx:\n",
    "    print token.orth_, token.dep_, token.head, [t.orth_ for t in token.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i hope none of us gets sick tonight . i did order food not poisoning . i do think you should come here because i got food not poisoning .\n"
     ]
    }
   ],
   "source": [
    "def transform_doc_1(doc): \n",
    "    #if root of sentence had negation and sentence contained kw\n",
    "    kw = ['poisoning', 'sick']\n",
    "    neg = ['not', \"n't\", 'no', 'none', 'nobody', 'neither']\n",
    "    parsedDoc = parser(doc.lower())\n",
    "    tokens = [[t.orth_ for t in s] for s in parsedDoc.sents] #this will be modified\n",
    "    sents = list(parsedDoc.sents)\n",
    "    for i in range(len(sents)):\n",
    "        # each span has only one root\n",
    "        if not any([c.orth_ in neg for c in sents[i].root.children]): continue #if there's no negation\n",
    "        neg_i = [j for j in range(len(sents[i])) if sents[i][j].orth_ in neg][0]\n",
    "        kw_list = [j for j in range(len(sents[i])) if sents[i][j].orth_ in kw]\n",
    "        \n",
    "        if len(kw_list) == 0: continue\n",
    "        \n",
    "        kw_i = kw_list[0]\n",
    "        \n",
    "        #now modify\n",
    "        tokens[i].insert(kw_i, \"not\")\n",
    "        tokens[i].pop(neg_i)\n",
    "    #now we join everything with spaces\n",
    "    out = []\n",
    "    for sent in tokens:\n",
    "        out.append(\" \".join(sent))\n",
    "    return \" \".join(out)\n",
    "\n",
    "print transform_doc_1(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i hope of us gets not sick tonight . i did order food not poisoning . i do not think you should come here because i got food poisoning .\n"
     ]
    }
   ],
   "source": [
    "def transform_doc_2(doc): \n",
    "    #if negation and kw share a head\n",
    "    kw = ['poisoning', 'sick']\n",
    "    neg = ['not', \"n't\", 'no', 'none', 'nobody', 'neither']\n",
    "    parsedDoc = parser(doc.lower())\n",
    "    tokens = [[t.orth_ for t in s] for s in parsedDoc.sents] #this will be modified\n",
    "    sents = list(parsedDoc.sents)\n",
    "    for i in range(len(sents)):\n",
    "        if not any([c.orth_ in neg for c in sents[i]]): continue #if there's no negation\n",
    "        neg_list = [j for j in range(len(sents[i])) if sents[i][j].orth_ in neg]\n",
    "        kw_list = [j for j in range(len(sents[i])) if sents[i][j].orth_ in kw]\n",
    "        \n",
    "        if len(kw_list) == 0: continue\n",
    "        \n",
    "        # attempt at handling double negatives\n",
    "        double_negative = True\n",
    "        kw_i = -1\n",
    "        neg_i = -1\n",
    "        \n",
    "        for j in neg_list:\n",
    "            for k in kw_list:\n",
    "                if sents[i][j].head == sents[i][k].head and double_negative:\n",
    "                    neg_i = j\n",
    "                    kw_i = k\n",
    "                    double_negative = False\n",
    "                elif sents[i][j].head == sents[i][k].head and not double_negative:\n",
    "                    double_negative = True\n",
    "        \n",
    "        if double_negative: continue\n",
    "        \n",
    "        #now modify\n",
    "        tokens[i].insert(kw_i, \"not\")\n",
    "        tokens[i].pop(neg_i)\n",
    "    #now we join everything with spaces\n",
    "    out = []\n",
    "    for sent in tokens:\n",
    "        out.append(\" \".join(sent))\n",
    "    return \" \".join(out)\n",
    "\n",
    "print transform_doc_2(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "class NegationTransformer(TransformerMixin):\n",
    "    \"\"\" Brings negation words closer to relevant key terms to make it detectable with n-gram detector \"\"\"\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return np.array([transform_doc_2(doc) for doc in X])\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('negTransformer', <__main__.NegationTransformer object at 0x1a0eac890>), ('oldPipe', Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.95,...y='l2', random_state=57, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('negTransformer', NegationTransformer()), ('oldPipe', sick)])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.996213974705\n",
      "True positive :: 0.524425287356\n",
      "False negative :: 0.00862068965517\n",
      "False positive :: 0.00718390804598\n",
      "True negative :: 0.459770114943\n",
      "FP / TP :: 0.013698630137\n",
      "FN / TN :: 0.01875\n",
      "CPU times: user 22.3 s, sys: 342 ms, total: 22.6 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%time analyze(reviews, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.999638616417\n",
      "True positive :: 0.530465949821\n",
      "False negative :: 0.00358422939068\n",
      "False positive :: 0.0179211469534\n",
      "True negative :: 0.448028673835\n",
      "FP / TP :: 0.0337837837838\n",
      "FN / TN :: 0.008\n",
      "CPU times: user 4.27 s, sys: 70.6 ms, total: 4.34 s\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%time analyze(reviews2, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try refitting the pipeline?\n",
    "pipe1 = Pipeline([('negTransformer', NegationTransformer()), ('oldPipe', sick)])\n",
    "pipe2 = Pipeline([('negTransformer', NegationTransformer()), ('oldPipe', sick)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fitting against reviews from scratch\n",
    "from sklearn import cross_validation\n",
    "data = {}\n",
    "data['X'] = [review['text'] for review in reviews]\n",
    "data['y'] = [review['label'] for review in reviews]\n",
    "#folds = cross_validation.StratifiedKFold(data['y'], n_folds=3, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from yelp classifier training notebook\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "def my_roc_auc(ground_truth, predictions):\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    predictions = np.array(predictions)\n",
    "    return metrics.roc_auc_score(ground_truth, predictions, average='micro')\n",
    "\n",
    "my_roc_auc_scorer = metrics.make_scorer(my_roc_auc, needs_threshold=True, greater_is_better=True)\n",
    "# Feature Extractors\n",
    "cv = CountVectorizer(\n",
    "        input=u'content', \n",
    "        encoding=u'utf-8', \n",
    "        decode_error=u'strict', \n",
    "        strip_accents='unicode', \n",
    "        lowercase=True,\n",
    "        analyzer=u'word', \n",
    "        preprocessor=None, \n",
    "        tokenizer=None, \n",
    "        stop_words='english', \n",
    "        #token_pattern=u'(?u)\\\\b\\w\\w+\\b', # one alphanumeric is a token\n",
    "        ngram_range=(1, 2), \n",
    "        max_df=.9, \n",
    "        min_df=2, \n",
    "        max_features=None, \n",
    "        vocabulary=None, \n",
    "        binary=False, \n",
    "        #dtype=type 'numpy.int64'>\n",
    "        )\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf = TfidfTransformer(\n",
    "        norm='l2',\n",
    "        use_idf=True,\n",
    "        smooth_idf=True,\n",
    "        sublinear_tf=False\n",
    ")\n",
    "\n",
    "# Final Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "lr = LogisticRegression(C=.05,\n",
    "                        fit_intercept=True,\n",
    "                        random_state=0,\n",
    "                        class_weight='balanced',\n",
    "                        n_jobs=-1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('negtransform', NegationTransformer()),\n",
    "    ('count', cv),\n",
    "    ('tfidf', tf),\n",
    "    ('logreg', lr)\n",
    "    ])\n",
    "\n",
    "# param_grid = {\n",
    "#     'count__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "#     'tfidf__norm':['l1', 'l2'],\n",
    "#     'tfidf__use_idf':[True, False],\n",
    "#     'tfidf__sublinear_tf':[True,False],\n",
    "#     'logreg__C':[.001, .01, .1]\n",
    "# }\n",
    "param_grid = {\n",
    "    'count__ngram_range': [(1, 3)],\n",
    "    'count__max_df' : [ .95],\n",
    "    'count__stop_words': [None],\n",
    "    'count__lowercase' : [True],\n",
    "    'count__max_features': [None],\n",
    "    'tfidf__use_idf' : [True],\n",
    "    'tfidf__norm': [('l2')],\n",
    "    'logreg__C': [100],\n",
    "    'logreg__dual' : [True],\n",
    "    'logreg__fit_intercept': [True],\n",
    "    'logreg__penalty': ['l2'],\n",
    "    'logreg__intercept_scaling':[.01],\n",
    "    'logreg__random_state': [57],\n",
    "    'logreg__solver': ['liblinear']\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, \n",
    "                           param_grid,\n",
    "                           #cv = folds,\n",
    "                           scoring=my_roc_auc_scorer,\n",
    "                           n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Dev data shape:  (1113,) (1113,)\n",
      "Test data shape:  (279,) (279,)\n"
     ]
    }
   ],
   "source": [
    "def split_dev_test(data, test_size=.2):\n",
    "    train_data = {'X': [], 'y': [] }\n",
    "    test_data = {'X': [], 'y': [] }\n",
    "    for train, test in cross_validation.StratifiedShuffleSplit([a['label'] for a in reviews], n_iter=1, test_size=test_size, random_state=0):\n",
    "        train_data['X'] = np.array([data[i]['text'] for i in train])\n",
    "        train_data['y'] = np.array([data[i]['label'] for i in train])\n",
    "        test_data['X'] = np.array([data[i]['text'] for i in test])\n",
    "        test_data['y'] = np.array([data[i]['label'] for i in test])\n",
    "        \n",
    "    print \"Training/Dev data shape: \", train_data['X'].shape, train_data['y'].shape\n",
    "    print \"Test data shape: \",test_data['X'].shape, test_data['y'].shape\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = split_dev_test(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "CPU times: user 19 s, sys: 601 ms, total: 19.6 s\n",
      "Wall time: 50.5 s\n",
      "()\n",
      "Best score: 0.886\n",
      "Best parameters set:\n",
      "\tcount__lowercase: True\n",
      "\tcount__max_df: 0.95\n",
      "\tcount__max_features: None\n",
      "\tcount__ngram_range: (1, 3)\n",
      "\tcount__stop_words: None\n",
      "\tlogreg__C: 100\n",
      "\tlogreg__dual: True\n",
      "\tlogreg__fit_intercept: True\n",
      "\tlogreg__intercept_scaling: 0.01\n",
      "\tlogreg__penalty: 'l2'\n",
      "\tlogreg__random_state: 57\n",
      "\tlogreg__solver: 'liblinear'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   29.7s finished\n"
     ]
    }
   ],
   "source": [
    "%time grid_search.fit(train_data['X'], train_data['y'])\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "CPU times: user 20 s, sys: 576 ms, total: 20.6 s\n",
      "Wall time: 48.6 s\n",
      "Best score: 0.886\n",
      "ROC_AUC SCORE :: 0.886112545173\n",
      "True positive :: 0.433691756272\n",
      "False negative :: 0.100358422939\n",
      "False positive :: 0.10394265233\n",
      "True negative :: 0.362007168459\n",
      "FP / TP :: 0.239669421488\n",
      "FN / TN :: 0.277227722772\n",
      "CPU times: user 4.11 s, sys: 36 ms, total: 4.14 s\n",
      "Wall time: 4.22 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   27.0s finished\n"
     ]
    }
   ],
   "source": [
    "def split_and_test(data, grid_search, test_size=.2):\n",
    "    train_data = {'X': [], 'y': [] }\n",
    "    test_data = {'X': [], 'y': [] }\n",
    "    for train, test in cross_validation.StratifiedShuffleSplit([a['label'] for a in reviews], n_iter=1, test_size=test_size, random_state=0):\n",
    "        train_data['X'] = np.array([data[i]['text'] for i in train])\n",
    "        train_data['y'] = np.array([data[i]['label'] for i in train])\n",
    "        test_data['X'] = np.array([data[i]['text'] for i in test])\n",
    "        test_data['y'] = np.array([data[i]['label'] for i in test])\n",
    "        %time grid_search.fit(train_data['X'], train_data['y'])\n",
    "        print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "        %time analyze([{'text': a, 'label': b} for (a,b) in zip(test_data['X'],test_data['y'])], grid_search.best_estimator_)\n",
    "\n",
    "split_and_test(reviews, grid_search)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "CPU times: user 6.95 s, sys: 495 ms, total: 7.45 s\n",
      "Wall time: 8.23 s\n",
      "Best score: 0.890\n",
      "ROC_AUC SCORE :: 0.887816210635\n",
      "True positive :: 0.451612903226\n",
      "False negative :: 0.0824372759857\n",
      "False positive :: 0.114695340502\n",
      "True negative :: 0.351254480287\n",
      "FP / TP :: 0.253968253968\n",
      "FN / TN :: 0.234693877551\n",
      "CPU times: user 185 ms, sys: 4.49 ms, total: 189 ms\n",
      "Wall time: 193 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.0s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid_temp = {\n",
    "    'count__ngram_range': [(1, 3)],\n",
    "    'count__max_df' : [ .95],\n",
    "    'count__stop_words': [None],\n",
    "    'count__lowercase' : [True],\n",
    "    'count__max_features': [None],\n",
    "    'tfidf__use_idf' : [True],\n",
    "    'tfidf__norm': [('l2')],\n",
    "    'log__C': [100],\n",
    "    'log__dual' : [True],\n",
    "    'log__fit_intercept': [True],\n",
    "    'log__penalty': ['l2'],\n",
    "    'log__intercept_scaling':[.01],\n",
    "    'log__random_state': [57],\n",
    "    'log__solver': ['liblinear']\n",
    "}\n",
    "split_and_test(reviews, GridSearchCV(sick, \n",
    "                           param_grid_temp,\n",
    "                           scoring=my_roc_auc_scorer,\n",
    "                           n_jobs=1, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.886112545173\n",
      "True positive :: 0.433691756272\n",
      "False negative :: 0.100358422939\n",
      "False positive :: 0.10394265233\n",
      "True negative :: 0.362007168459\n",
      "FP / TP :: 0.239669421488\n",
      "FN / TN :: 0.277227722772\n",
      "CPU times: user 4.17 s, sys: 50.7 ms, total: 4.22 s\n",
      "Wall time: 4.31 s\n"
     ]
    }
   ],
   "source": [
    "%time analyze([{'text': a, 'label': b} for (a,b) in zip(test_data['X'],test_data['y'])], grid_search.best_estimator_)\n",
    "#TODO: format reviews in X and y arrays instead of individual objects..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC SCORE :: 0.886164171399\n",
      "True positive :: 0.433691756272\n",
      "False negative :: 0.100358422939\n",
      "False positive :: 0.10394265233\n",
      "True negative :: 0.362007168459\n",
      "FP / TP :: 0.239669421488\n",
      "FN / TN :: 0.277227722772\n",
      "CPU times: user 4.26 s, sys: 45.2 ms, total: 4.31 s\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%time analyze(reviews2, grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992694891784\n",
      "After posting my original review, the NYC Health Dept contacted me and urged me to call 311 to report the food poisoning incident at Atlas Cafe.  I would like to clarify I did not contract food poisoning from Atlas Cafe.  I merely likened the urgency to post my one star review of Atlas to my urgency to use the bathroom when I did contract food poisoning from a wedding in Jersey.\n",
      "\n",
      "0.996696994241\n",
      "After reading all the rave reviews about Schnitzi, I finally decided to try it out. What a mistake!!!\n",
      "The place is filthy, the menu prices are too high and the food sucks. I tried their double burger. They barely put tomatoes or pickles in my sandwich. The sauce wasn&#39;t that great, but the worst part was the meat. The burgers were two pieces of rubber that tasted horrible.\n",
      "All night I was burping nasty burps that felt like I ate a whole rotten cow. The next day I was still sick from this crappy burger and all my clothes smelled of filthy food.\n",
      "I don&#39;t recommend this place to anyone.\n",
      "\n",
      "0.835998639613\n",
      "After waiting 2 hours for a table, I think my expectations were too high for this place. \n",
      "\n",
      "I would give it 4 stars but my friend and I had really bad indigestion or some stomach problems right after eating the butter drench, garlic food.\n",
      "\n",
      "We got the Shrimp and Crawfish combo, snowcrab and the lobster and crawfish.. the lobster combo was $40 because it&#39;s &#34;marketprice&#34; but why wouldn&#39;t they just have that on the menu?\n",
      "\n",
      "The shrimp and the snowcrabs were my favorite the cajun wings were really juicy and flavorful. I really like garlic (not powder, salt, seasoning) raw garlic and the boil uses LOTS of it.\n",
      "\n",
      "After  20 minutes into eating, I felt sick and the food was too greasy with butter so I asked for rice, which the server got the saddest side of rice which didn&#39;t even look like a bowl of rice but a square of rice... I didn&#39;t even know rice could all mesh together like mash potato and be shaped that way. On top of that I was charged $3 for it.\n",
      "\n",
      "\n",
      "\n",
      "cash only. ugh.\n",
      "\n",
      "0.530232927818\n",
      "BEWARE:  Unclean and Unsafe COOKING PRACTICE!  The worst diner experience of my life.  The waiter rushed my party and other tables around us to order our food.  The waiter asked specifically what type of milk or creamer we need for our coffee and failed to deliver.  He forgot to put butter on my friends toasts.  My omelette was under cooked and after all the other mistakes I went to the counter to complain.  The manager said he will take care of it.  they just slapped the same omelette back in the grill and gave it to me burnt and half the potatoes were gone.  I didn't even touch/eat any of the food prior.  I had to send it back again.  I will never eat here again... I will tell everyone not to eat here cuz it's just plain awful!!  BelAire Diner why did u slap the same omelette back on the grill?  Why didn't you make me a new one?  I don't think it's very Sanitary to put food that was served on someone else's table and attempt to cook it again on the same grill w/ other patrons food?  BelAire Diner, how do you know I'm not sick?  Or have some crazy disease?  Have you practiced this before when other patrons send back food?  SHAME ON YOU!!!\n",
      "\n",
      "0.553305003585\n",
      "came here for dinner.\n",
      "\n",
      "seated in garden.\n",
      "sick ambiance. \n",
      "trees and bushes in the middle of the restaurant.\n",
      "definitely felt like i was in a park.\n",
      "roomy restaurant.\n",
      "nice looking bar.\n",
      "\n",
      "ordered a speciality cocktail- tasted absolutely horrible. so bad i had to change it. literally tasted like lysol. plus it took 15-20 minutes for it to come.\n",
      "\n",
      "lamb meatballs- not bad at all. were tasty.\n",
      "\n",
      "pizza- very average. have had better slices at corner pizza shops.\n",
      "\n",
      "friend had the salmon- very salty. almost unbearable.\n",
      "\n",
      "i had rigatoni- very weak. almost tasteless.\n",
      "\n",
      "overall really nice setting, but food was very bland.\n",
      "\n",
      "0.984862465723\n",
      "Good summer time bar stop.  They have a rooftop which is pretty cool.  There is a good selection of beers as well.  I've been here half a dozen times and always enjoyed the experience.\n",
      "\n",
      "Only reason I'm not gonna give this 5 stars is I got food poisoning the last time I was there after ordering a turkey burger.  I didn't eat anything else that day and it took days to pass.\n",
      "\n",
      "0.999599816973\n",
      "Got sick after eating their food truck burger.\n",
      "\n",
      "Stay away!\n",
      "\n",
      "0.649369246119\n",
      "Has been going downhill in terms of the food quality and portion size.  String beans are not supposed to be the color of baby's diarrhea and the texture of the mashed potatoes-they have to be bright green and crispy, not mushy.  Staff needs to learn how to count-if small plate is 3 meatballs and large is 5, don't give me 4 meatballs with the large plate, that's cheating.  The servings for the sides used to be heaping spoons, now, they barely cover the spoon.  Was great, now seems more like a rip-off.\n",
      "\n",
      "0.732543562394\n",
      "I discovered this place after I started working in Chelsea and i was looking for a less corporate go-to coffee shop for my morning caffeine kick. It didn&#39;t take long for me to get addicted to their selection of coffees and baked muffins leading to me getting their lunch sandwiches as well. After frequenting the cafe more than 13 times within 10 business days I encountered my first MOLDY MUFFIN! The worst part is, the mold was forming on the bottom rim of the muffin and because I was eating it from the top, I didn&#39;t notice until I was midway through! In Shock, I brought the other half back to the cafe and even the cashier was stunned after I showed her! She apologized and in the midst of the moment (she may have been struck by stupidity) but asked me if I wanted another muffin rather than a refund. I&#39;m not the type of person to make a scene so I kindly declined and got my money back.\n",
      "I was so upset over this incident, not so much about the mold (since it did not make me sick) but because their food tasted SOOOOOOOOOO good and now I didn&#39;t feel like I could trust their quality.\n",
      "I waited approximately 1 week and couldn&#39;t resist the urge any longer...I decided to go back and get their parmesian eggplant sandwich. If this visit had no issues I definitely would still go there, but it may have been a coincidence where the large piece of cheese on my sandwich looked as though there were little white/clear fuzzy things on it! I COULD NOT BELIEVE MY EYES! I asked my co-worker to look at it confirming it was mold! I really wanted to give them the benefit of the doubt and believe it was pieces of the wax paper stuck to the cheese, but wax paper just doesn&#39;t leave that type of fuzzy residue. I was so disappointed, not to mention I did get a stomach ache this time from the food.  I really wish this place would just carry more &#34;fresh&#34; food items, practice better hygiene (maybe just check the muffins they leave sitting out in the pan), because I honestly did LOVE the food here.  I just can&#39;t bring myself to go here anymore because I&#39;m scared of what is going to be growing on/in my food...Not to mention the employees are super nice. *sigh* Another good place lost\n",
      "\n",
      "0.739888706081\n",
      "I recently went to an event at Barclays with some friends and walked out starving.  Most of the Park Slope restaurants are closed by 11:30.  I&#39;d been to 200 5th a few years ago and it was solid.  Good beer selection, solid bar food.  \n",
      "\n",
      "The recent experience was nothing like the past ones.  First round of beers comes, one is skunked.  It happens, I think nothing of it.  Waitress is totally cool with letting a change happen.  Different beer comes, it&#39;s skunked again!  \n",
      "\n",
      "Honey wings, very good.  Since I can&#39;t give this experience 0 stars, the honey wings are reason for a star.  \n",
      "\n",
      "The entrees ordered should have been layups.  Burger, turkey burger and grilled cheese.  It&#39;s not like we ordered the fish and chicken cordon bleu.  I ate the burger because I&#39;m a dude and I was starving, but I was praying for no food poisoning when I got home.  The meat tasted old.  The bun was dry and tasteless.  It was so horrible that I removed the burger/cheese/veggies and ate it separately.  I should have sent everything back but at this point it would have been a pointless exercise.  I just needed to get out of there.\n",
      "\n",
      "The curly fries were average, not bad.  Friend got onion rings on the side, decent also.   \n",
      "\n",
      "I&#39;m disappointed by experience here.  It&#39;s a great setup for a game.  I&#39;d say if you are going here get the wings and beer on bottle to keep it simple and safe.\n",
      "\n",
      "0.509107681536\n",
      "I should have heeded the other negative reviews, but I was too enticed by the $3.95 all you can drink bloody marys, and for that I was punished with RAW EGGS.\n",
      "\n",
      "I ordered Uova Al Forno (eggs baked with tomato sauce and oregano). It arrived barely warmer than room temperature, but I decided sending it back would have taken forever... big mistake. About halfway through, I got a big mouthful of RAW egg white which I had to spit out into my napkin. 24 hours later, I still can't get the feeling of it out of my mouth, but luckily at least I'm not violently sick from salmonella. The triangle shaped latke it came with was also cold, greasy, and completely tasteless.\n",
      "\n",
      "To top it off, something was floating in my friend's water glass, and it took a long time to flag someone down to ask for a change of water, and a refill on mine. The bloody marys were ok, but so full of horseradish that it was kind of gross after a while. The refills also arrive warm (they pour from a room temperature carafe) and it was next to impossible to get the waitress' attention to ask for ice. I should note that the woman refilling our drinks was lovely and very sweet. The other waitress was totally aloof until it was time for us to pay. The bill was on the table 2 seconds after they picked up our plates, without even asking if we needed anything else or how the food was (I never got a chance to tell anyone about my raw plate of gross-ness). At least the coffee was delicious (although we were never offered a refill).\n",
      "\n",
      "0.714139248852\n",
      "I used to like the place but I must say this one and the one on northern blvd both stink greasy salty lousy food never again makes me sick\n",
      "\n",
      "0.842791668015\n",
      "I would give zero if I could. This is the worst Restaurant I have ever been at! \n",
      "\n",
      "We only went in to that Taco bell because it was 96 degrees outside and we wanted to get some cool Air. The place we originally wanted to stay at had no AC and basically yelled food poisoning but would have been the better choice.\n",
      "\n",
      "So, let&#39;s start with the completely depressing, run down look. We where the only customers  on a Saturday afternoon. Most of the tables where really dirty and the chairs had ripped and worn off. \n",
      "\n",
      "When I ordered my food, the casher was completely unable to use the register. It took him like 10 minutes to take my order, he got it wrong and charged me more than it was, since he was unable to figure our the lunch-box thing... He then forgot my cup and after I asked for it, he gave me neither a straw nor a lid. \n",
      "\n",
      "i ate half of the food that he gave me, then threw it away since i was to afraid to get food poisoning and it tasted like nothing. \n",
      "\n",
      "I was so glad to get out of there and swore to myself: never again!\n",
      "\n",
      "0.753026815183\n",
      "It&#39;s decent cheap American-Chinese food.  I don&#39;t understand the negative reviews.  Also they have an A health code rating, which 2 of the local competitors do not.  At least I know I&#39;m not going to get sick after eating here.  They are very nice people too.\n",
      "\n",
      "0.691944514218\n",
      "Just had lunch here today after coworkers had been bragging about it for weeks as the best cheap sushi in manhattan.\n",
      "\n",
      "But really, does one really want to combine the word cheap with raw fish? Ramen I can understand as all that steamy broth kills the deadly microbes. But i dunno, New York. I guess we all live knowing we're a short ambulance ride from the ER and so we live dangerously.\n",
      "\n",
      "That said the waitress was cool. I ordered a la carte and asked her if I ordered properly. She said' \"Yes, better than my boyfriend\" and we both laughed. \n",
      "\n",
      "The food came. Everything tasted fresh but they serve the fish in pieces that are way too large (Americanized?) I hate that. \n",
      "\n",
      "Miso soup was delicious. As I finished my last slurp behold, a cockroach hiking over my chopstick wrapper. :(\n",
      "\n",
      "I didn't get sick. Food was quite good. Ambiance - meh. Cockroach? A neutral three stars.\n",
      "\n",
      "0.737458050091\n",
      "Ordered delivery for the first and last time tonight. The estimate delivery time they gave me was 37 minutes, after one hour of waiting I called and the man on the phone told me it had just left... No apologizes for the delay or anything. 30 minutes later I finally got the food, that took a total of an hour and a half to get here. \n",
      "\n",
      "The falafel and dynamite sandwich we ordered tasted like they had been sitting in the delivery bike for way too long. Falafel was cold and dry, the pita wrap was soggy...\n",
      "\n",
      "We also ordered hummus and baba ganoush which are hard to mess up. They both felt like they had just been taken out of a freezer, they were chunky and very cold. The baba ganoush had a weird tone and smell to it so we didn&#39;t eat it, and the hummus had a weird chunky consistency and was half frozen as well. The pita bread that we ordered to go with it was equally bad. Dry, tasted like cardboard, I could have bought a better pita bread at the corner store. It&#39;s hard to mess up mediterranean food as long as you use fresh ingredients, but this place didn&#39;t do a single thing right. They also forgot our salad, but I didn&#39;t bother to call about it seeing the quality of their other food. \n",
      "\n",
      "Only pro is that I didn&#39;t get food poisoning.\n",
      "\n",
      "0.817087413957\n",
      "Stuffed cabbage had more potato than meat. String beans were mush and inedible. Beats were mush and... Weird. I felt sick after my meal, half of which I didn&#39;t eat. The only good part was that the servers were friendly and welcoming.\n",
      "\n",
      "0.817619075914\n",
      "The burrito I had (carnitas + black beans) didn't insult my mother or give me food poisoning, so hey, it's still a burrito. I imagine your enjoyment level will be directly related to your inebriation level. \n",
      "\n",
      "Pros:\n",
      "* burrito was sufficiently enormous\n",
      "* burrito was cheap (less than $8)\n",
      "* fast service\n",
      "\n",
      "Cons:\n",
      "* bland, bland, bland. \n",
      "* this place had a B rating from the health and safety board. You deserve better, but if you're like me, you probably won't care. \n",
      "\n",
      "2 stars because there's so much better to be had. Make the hike to calexico if you really want a burrito ($$) or, I dunno, try somewhere else ($?)\n",
      "\n",
      "0.976706055794\n",
      "The worst Brazilian restaurant I&#39;ve ever eaten. My husband ordered a medium steak and I ordered a medium well.... We  both got well done, hard steaks that we couldn&#39;t finish. I got really sick of my stomach. I&#39;ll never go back, and won&#39;t recommend. BTW, I am Brazilian, I know my !@#$%^&amp;*\n",
      "\n",
      "0.811481319052\n",
      "There is a reason that this is the only place that will have guaranteed seating available for dinner in Little Italy.  Because the food here is terrible.  The only people you'll see eating here are disappointed tourists and people that will soon be spending the rest of their evening and entire next day fighting food poisoning.  The calamari tasted like it was fried in old oil that leaked from an old tailpipe.  The pizza was a pathetic flat depressing pie that tasted of freezer burn and not much else. The grappa I'm currently trying to swallow - swill.  On the bright side, I'm walking out of here soon, so that's one star...and the service was good.  (I feel sorry for the poor people that have to serve this food).\n",
      "\n",
      "0.62559589812\n",
      "This is a review on Cooler Cleanse from Juice Generation. I decided to do a 3-day juice cleanse with my friend. We both had no experience with juice cleansing, but thought we would give it a try. We were trying to obtain that \"energetic\" \"detoxed\" feeling that everyone speaks about!\n",
      "\n",
      "Well, we both hated the juices. They were in no way filling and extremely sweet or extremely sour (spicy lemonade). In no way did we feel satisfied, tired, energetic, or \"cleansed.\" We both felt sick, hungry, and irritated at the cost of this 3-day cleanse ($170) and the ripped-off feeling we had. Both of us felt sick and ended the cleanse a day early. Juice generation cooler cleanse called to ask how I was feeling. I told her I was sick, really did not enjoy it, and didn't feel well, (even today a few days later I'm still not functioning normally!) all she said was \"let me know if you have any other questions or comments.\" I would NOT recommend this. It is a marketing/advertising trap!!!!\n",
      "\n",
      "0.51744133234\n",
      "This place should get zero stars. Yes the food was tasty and authentic AND I personally love a good \"hole in the wall\" AND can tolerate a little dinginess in my eating establishment, BUT this place was filthy! I even tolerated the people handling my food with their bare, grimy hands, but when roaches started crawling on the table while I was eating, I had to draw the line. I completely lost my appetite so I threw away my food and left. Then I looked and saw that their grade from the DOH was pending. Looked up why and found out that the health inspectors came to the same conclusion as I did!\n",
      "\n",
      "So, I agree with the other reviews that the food is memorable but the unsanitary conditions are unacceptable and dangerous. Someone will get sick, likely already has. I would prefer they increase their prices, buy some gloves for food handling and hire a cleaning service. You have an authentic product, so have some pride in your establishment and respect for your customers.\n",
      "\n",
      "0.617528397751\n",
      "This review isn&#39;t about the ambiance, the people, or the sports. I am giving it an extra star because the trivia night was fun.\n",
      "\n",
      "This review is about the food and drinks which are an important component to any worthwhile after work bar visit. Come here if you have extra money to throw away on nothing. I had the worst pour with a cup full of ice on both of my $11 drinks. It felt like it was a glass o watery soda with a tiny splash of alcohol. Stingiest pours ever. I get way better at $3 happy hours at many bars in LES. I felt completely ripped off. I wish I asked how much the drink was before I ordered a second. \n",
      "\n",
      "Hand down the worst bar food I have ever eaten. Chicken fingers were gross, and the nachos made me sick to my stomach.\n",
      "\n",
      "Despite it being steps away from my house...Royal I will not be back.\n",
      "\n",
      "0.815592593969\n",
      "Totally overrated, waited about an hour for a table. We had the mussels (bland and my friend said the freshness was questionable and as much as i love food poisoning, no thanks) the gnocchi (couldn&#39;t finish it, it had this odd bitter taste) and the flan (the best thing we had there and thats not really an italian dessert)You&#39;re also forced to listen to other guests conversations since they are basically sitting on your lap... However, prices are decent...\n",
      "\n",
      "0.814158236634\n",
      "Very bad food and service. \n",
      "We ordered chicken and pasta and the food came faster than in any fast food restaurant.\n",
      "The food itself was terrible and we didn't finish our plate as we were scared to be sick.\n",
      "The waiter was rude.\n",
      "It's a pity because the restaurant itself is very unique (decoration, live music).\n",
      "But i will not come back .\n",
      "\n",
      "0.794663379694\n",
      "WARNING:  This place can be pretty rough if you have any stomach issues.\n",
      "\n",
      "So I wrote a review right after getting home from this place.  Unfortunately, my review has to change.  I was feeling full when I got home after eating here, and it only got worse.  I couldn't sleep till 3am (I ate there at 8pm), and even when I woke up I felt like I had something stuck in my stomach.  It was a feeling of being super full, my stomach just pushing against my clothes.  Felt so uncomfortable that I couldn't sleep.  Mind you, I have GERD, but haven't had any issues for months.  Also, my friend that took me there told me her friend with IBS ate here and felt horribly sick afterwards.  I don't know if it's all the fiber but something's up.  Thus, went down from 3 to 2 stars.  Just not for me.\n",
      "\n",
      "\n",
      "Original Review:  \n",
      "\n",
      "The shakes were great, had the Red Coconut one and I could taste both the strawberries and the coconut.  Very filling, like I would have been fine with just shake.\n",
      "\n",
      "Mexican platter was good, but I didn't care for the rice.\n",
      "\n",
      "Overall, it was good, not extremely flavorful, and maybe a bit too pricey.  Just OK for me.\n",
      "\n",
      "0.82009260395\n",
      "We decided to try our hand making linguine and clams after getting sick of paying $20+ to get a subpar version at different restaurants. The main problem was finding clams fresh enough for the dish. The last time a friend picked up &#34;fresh&#34; fish at Whole Foods, he had food poisoning. Yelp reviews led us to Rosendo where we got a dozen little neck clams that were on ice. After washing and cooking, every clam popped open and proved to be fresh. \n",
      "\n",
      "The place was a little tough to find considering the unassuming storefront and the wrong yelp address. All I remember is that it&#39;s near a Kumon. Man, I hate Kumon haha.\n",
      "\n",
      "0.512521181899\n",
      "We managed to catch Fatta Cuckoo on a bad day. Their chef had called in sick and the sous chef was left by himself in the kitchen to handle all the food orders. The writing was on the wall when we walked in. They messed up our reservation of 2, and had us sit at the bar but we got a free round of drinks so no hard feelings.\n",
      "\n",
      "We started off with the fried clam special. A bit bready but tasted fine.  We had ordered the burger and the fried chicken, but after waiting for over an hour since the arrival of our app, we still hadn&#39;t gotten them. They recognized this and gave us more free drinks. To give you an idea how backed up they were - our reso was at 730 but we didn&#39;t get our entrees until 915. Finally when my burger came, it was cooked medium well (I had ordered medium rare) and I had no choice but to send it back. To their credit, they gave me another burger within 10 minutes that was cooked much better.\n",
      "\n",
      "The short rib burger, at the correct temperature, was pretty good but not sure if it&#39;s worth the $22 price tag even though it does come with a beer. It could be due to the unfortunate case of not having the regular chef that night but while the meat was juicy, it lacked seasoning. The fried chicken wasn&#39;t too different. It was moist under the dark, crispy skin but the flavor didn&#39;t pop as much. Overall I&#39;d give the app and entrees 3.5/5\n",
      "\n",
      "We also got a free dessert on top all the drinks and apologies we got from the frustrated staff. I tried the chocolate cream pie which I thought was delicious and devoured in two minutes. \n",
      "\n",
      "One good thing that came out of going there on a off night was that because of the free drinks they gave us, we got to try a lot of the cocktails. Not The Girl Next Door was an excellent chili infused mescal cocktail that I&#39;d order over and over again. For something summery and light I would suggest Don&#39;t Tell Carly.\n",
      "\n",
      "Restaurants can have off nights due to unforeseen circumstances and I felt Fatta Cuckoo came through for us that night despite being in a very tough situation with the absence of the regular chef. We were also helped by a Travelzoo deal we had but I don&#39;t think I&#39;d want to pay their regular prices for the quality of food we received. However I&#39;m willing to give them the benefit of the doubt and come back here another time.\n",
      "\n",
      "FOOD: 3.5/5\n",
      "SERVICE: 5/5\n",
      "D?COR &amp; AMBIANCE: 3/5\n",
      "VALUE: 3.5/5 (4/5 with the Travelzoo deal)\n",
      "\n",
      "0.944431969028\n",
      "We went at an \"off\" time on an \"off\" day (Sunday evening, earlyish). That said, there shouldn't have been any issue getting our drinks in a timely manner as the place was quiet. Sadly, the service was so poor, we got up from our table twice to inquire about where our drinks were.\n",
      "\n",
      "The food was lackluster. I had the skirt steak. Although I'm not sick, it's sitting in my stomach like a rock -- not fun.\n",
      "\n",
      "This place was super skippable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def reveal_fp(reviews, classifier):\n",
    "    prediction = classifier.predict_proba([a['text'] for a in reviews])\n",
    "    for review, pred in zip(reviews, prediction):\n",
    "        if review['label'] == 0.0 and pred[1] > 0.5:\n",
    "            print pred[1]\n",
    "            print review['text']\n",
    "            print\n",
    "\n",
    "reveal_fp(reviews2, grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.95, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "        ...alty='l2', random_state=57, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2 = GridSearchCV(sick, \n",
    "                           param_grid,\n",
    "                           cv = folds,\n",
    "                           scoring=my_roc_auc_scorer,\n",
    "                           n_jobs=-1, verbose=1)\n",
    "sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x1028ef4b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/kevin...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x1028ef4b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/kevin...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    384     def start(self):\n    385         if self.poller is not None:\n    386             self.poller.start()\n    387         self.kernel.start()\n    388         try:\n--> 389             ioloop.IOLoop.instance().start()\n    390         except KeyboardInterrupt:\n    391             pass\n    392 \n    393 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    861                 self._events.update(event_pairs)\n    862                 while self._events:\n    863                     fd, events = self._events.popitem()\n    864                     try:\n    865                         fd_obj, handler_func = self._handlers[fd]\n--> 866                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    867                     except (OSError, IOError) as e:\n    868                         if errno_from_exception(e) == errno.EPIPE:\n    869                             # Happens when the client closes the connection\n    870                             pass\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    247         if self.control_stream:\n    248             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    249 \n    250         def make_dispatcher(stream):\n    251             def dispatcher(msg):\n--> 252                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    253             return dispatcher\n    254 \n    255         for s in self.shell_streams:\n    256             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}})\n    208         else:\n    209             # ensure default_int_handler during handler call\n    210             sig = signal(SIGINT, default_int_handler)\n    211             self.log.debug(\"%s: %s\", msg_type, msg)\n    212             try:\n--> 213                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['15B18E86CB1040EAB3CDC14267BDB3E4']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}}\n    214             except Exception:\n    215                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    216             finally:\n    217                 signal(SIGINT, sig)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['15B18E86CB1040EAB3CDC14267BDB3E4'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}})\n    357         if not silent:\n    358             self.execution_count += 1\n    359             self._publish_execute_input(code, parent, self.execution_count)\n    360 \n    361         reply_content = self.do_execute(code, silent, store_history,\n--> 362                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    363 \n    364         # Flush output before sending the reply.\n    365         sys.stdout.flush()\n    366         sys.stderr.flush()\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-62-d7cb5029435f>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3001 \n   3002         try:\n   3003             for i, node in enumerate(to_run_exec):\n   3004                 mod = ast.Module([node])\n   3005                 code = compiler(mod, cell_name, \"exec\")\n-> 3006                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>\n        self.user_global_ns = {'Business': <class 'foodbornenyc.models.businesses.Business'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Document': <class 'foodbornenyc.models.documents.Document'>, 'English': <class 'spacy.en.English'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"#from yelp classifier training notebook\\nfrom ...                           n_jobs=-1, verbose=1)\", u'from spacy.en import English\\nparser = English()', u'import foodbornenyc.models.models as models\\nf...rom foodbornenyc.models.metadata import metadata', u\"import xlrd\\nf = xlrd.open_workbook('data/yelp...sifier_data.xlsx')\\nsheet1 = f.sheet_by_index(0)\", u'from sklearn.externals import joblib\\nfrom foo... joblib.load(\"../\"+config[\\'model_file\\'])\\nsick', u'import numpy as np\\nfrom sklearn.metrics impor...t fp_rate / tp_rate\\n    print fn_rate / tn_rate', u'reviews = []\\nfor i, (rev, label) in enumerate...:rev.value, \"label\":label.value})\\nprint reviews', u'analyze(reviews, sick)', u'sheet2 = xlrd.open_workbook(\\'data/sick_test_p...rev.value, \"label\":label.value})\\nprint reviews2', u'analyze(reviews2, sick)', u'sick.steps', u'# key words to watch out for: poisoning, sick,..._, token.head, [t.orth_ for t in token.children]', u'def transform_doc_1(doc): \\n    #if root of se... \" \".join(out)\\n\\nprint transform_doc_1(example)', u'def transform_doc_2(doc): \\n    #if negation a... \" \".join(out)\\n\\nprint transform_doc_2(example)', u'from sklearn.base import TransformerMixin\\ncla...=None, **fit_params):\\n        return self\\n    ', u\"from sklearn.pipeline import Pipeline\\npipe = ...egationTransformer()), ('oldPipe', sick)])\\npipe\", u'analyze(reviews, pipe)', u'analyze(reviews2, pipe)', u\"#try refitting the pipeline?\\npipe1 = Pipeline...er', NegationTransformer()), ('oldPipe', sick)])\", ...], 'Location': <class 'foodbornenyc.models.locations.Location'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NegationTransformer': <class '__main__.NegationTransformer'>, ...}\n        self.user_ns = {'Business': <class 'foodbornenyc.models.businesses.Business'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Document': <class 'foodbornenyc.models.documents.Document'>, 'English': <class 'spacy.en.English'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"#from yelp classifier training notebook\\nfrom ...                           n_jobs=-1, verbose=1)\", u'from spacy.en import English\\nparser = English()', u'import foodbornenyc.models.models as models\\nf...rom foodbornenyc.models.metadata import metadata', u\"import xlrd\\nf = xlrd.open_workbook('data/yelp...sifier_data.xlsx')\\nsheet1 = f.sheet_by_index(0)\", u'from sklearn.externals import joblib\\nfrom foo... joblib.load(\"../\"+config[\\'model_file\\'])\\nsick', u'import numpy as np\\nfrom sklearn.metrics impor...t fp_rate / tp_rate\\n    print fn_rate / tn_rate', u'reviews = []\\nfor i, (rev, label) in enumerate...:rev.value, \"label\":label.value})\\nprint reviews', u'analyze(reviews, sick)', u'sheet2 = xlrd.open_workbook(\\'data/sick_test_p...rev.value, \"label\":label.value})\\nprint reviews2', u'analyze(reviews2, sick)', u'sick.steps', u'# key words to watch out for: poisoning, sick,..._, token.head, [t.orth_ for t in token.children]', u'def transform_doc_1(doc): \\n    #if root of se... \" \".join(out)\\n\\nprint transform_doc_1(example)', u'def transform_doc_2(doc): \\n    #if negation a... \" \".join(out)\\n\\nprint transform_doc_2(example)', u'from sklearn.base import TransformerMixin\\ncla...=None, **fit_params):\\n        return self\\n    ', u\"from sklearn.pipeline import Pipeline\\npipe = ...egationTransformer()), ('oldPipe', sick)])\\npipe\", u'analyze(reviews, pipe)', u'analyze(reviews2, pipe)', u\"#try refitting the pipeline?\\npipe1 = Pipeline...er', NegationTransformer()), ('oldPipe', sick)])\", ...], 'Location': <class 'foodbornenyc.models.locations.Location'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NegationTransformer': <class '__main__.NegationTransformer'>, ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/Users/kevinzeng/FoodborneNYC/notebooks/<ipython-input-62-d7cb5029435f> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 grid_search2.fit(np.array(data['X']), data['y'])\n      7 print()\n      8 \n      9 print(\"Best score: %0.3f\" % grid_search2.best_score_)\n     10 print(\"Best parameters set:\")\n     11 best_parameters2 = grid_search2.best_estimator_.get_params()\n     12 for param_name in sorted(param_grid.keys()):\n     13     print(\"\\t%s: %r\" % (param_name, best_parameters2[param_name]))\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...rer(my_roc_auc, needs_threshold=True), verbose=1), X=array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...])\n    799         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    800             Target relative to X for classification or regression;\n    801             None for unsupervised learning.\n    802 \n    803         \"\"\"\n--> 804         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...er(my_roc_auc, needs_threshold=True), verbose=1)>\n        X = array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952')\n        y = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]\n        self.param_grid = {'count__ngram_range': [(1, 1), (1, 2), (1, 3)], 'logreg__C': [0.001, 0.01, 0.1], 'tfidf__norm': ['l1', 'l2'], 'tfidf__sublinear_tf': [True, False], 'tfidf__use_idf': [True, False]}\n    805 \n    806 \n    807 class RandomizedSearchCV(BaseSearchCV):\n    808     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...rer(my_roc_auc, needs_threshold=True), verbose=1), X=array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    548         )(\n    549             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    550                                     train, test, self.verbose, parameters,\n    551                                     self.fit_params, return_parameters=True,\n    552                                     error_score=self.error_score)\n--> 553                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    554                 for train, test in cv)\n    555 \n    556         # Out is a list of triplet: score, estimator, n_test_samples\n    557         n_fits = len(out)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu May  5 21:20:01 2016\nPID: 49031     Python 2.7.9: /Users/kevinzeng/.virtualenvs/fbnyc/bin/python\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], make_scorer(my_roc_auc, needs_threshold=True), array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), 1, {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], make_scorer(my_roc_auc, needs_threshold=True), array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), 1, {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), X=memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], scorer=make_scorer(my_roc_auc, needs_threshold=True), train=array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), test=array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), verbose=1, parameters={'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1515     fit_params = fit_params if fit_params is not None else {}\n   1516     fit_params = dict([(k, _index_param_value(X, v, train))\n   1517                       for k, v in fit_params.items()])\n   1518 \n   1519     if parameters is not None:\n-> 1520         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...     tol=0.0001, verbose=0, warm_start=False))])>\n        parameters = {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n   1521 \n   1522     start_time = time.time()\n   1523 \n   1524     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), **params={'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True})\n    256                 name, sub_name = split\n    257                 if name not in valid_params:\n    258                     raise ValueError('Invalid parameter %s for estimator %s. '\n    259                                      'Check the list of available parameters '\n    260                                      'with `estimator.get_params().keys()`.' %\n--> 261                                      (name, self))\n        name = 'logreg'\n        self = Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))])\n    262                 sub_object = valid_params[name]\n    263                 sub_object.set_params(**{sub_name: value})\n    264             else:\n    265                 # simple objects case\n\nValueError: Invalid parameter logreg for estimator Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n        lowercase=True, max_df=0.95, max_features=None, min_df=1,\n        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n        ...alty='l2', random_state=57, solver='liblinear',\n          tol=0.0001, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-d7cb5029435f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgrid_search2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0;31m# a working pool as they expect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    157     pkg_name = mod_name.rpartition('.')[0]\n    158     main_globals = sys.modules[\"__main__\"].__dict__\n    159     if alter_argv:\n    160         sys.argv[0] = fname\n    161     return _run_code(code, main_globals, None,\n--> 162                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    163 \n    164 def run_module(mod_name, init_globals=None,\n    165                run_name=None, alter_sys=False):\n    166     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x1028ef4b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/kevin...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x1028ef4b0, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/kevin...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    384     def start(self):\n    385         if self.poller is not None:\n    386             self.poller.start()\n    387         self.kernel.start()\n    388         try:\n--> 389             ioloop.IOLoop.instance().start()\n    390         except KeyboardInterrupt:\n    391             pass\n    392 \n    393 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    861                 self._events.update(event_pairs)\n    862                 while self._events:\n    863                     fd, events = self._events.popitem()\n    864                     try:\n    865                         fd_obj, handler_func = self._handlers[fd]\n--> 866                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    867                     except (OSError, IOError) as e:\n    868                         if errno_from_exception(e) == errno.EPIPE:\n    869                             # Happens when the client closes the connection\n    870                             pass\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    247         if self.control_stream:\n    248             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    249 \n    250         def make_dispatcher(stream):\n    251             def dispatcher(msg):\n--> 252                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    253             return dispatcher\n    254 \n    255         for s in self.shell_streams:\n    256             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}})\n    208         else:\n    209             # ensure default_int_handler during handler call\n    210             sig = signal(SIGINT, default_int_handler)\n    211             self.log.debug(\"%s: %s\", msg_type, msg)\n    212             try:\n--> 213                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['15B18E86CB1040EAB3CDC14267BDB3E4']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}}\n    214             except Exception:\n    215                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    216             finally:\n    217                 signal(SIGINT, sig)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['15B18E86CB1040EAB3CDC14267BDB3E4'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', u'msg_type': u'execute_request', u'session': u'15B18E86CB1040EAB3CDC14267BDB3E4', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'1E98ACA7EBEF4F789B8396E4507419E2', 'msg_type': u'execute_request', 'parent_header': {}})\n    357         if not silent:\n    358             self.execution_count += 1\n    359             self._publish_execute_input(code, parent, self.execution_count)\n    360 \n    361         reply_content = self.do_execute(code, silent, store_history,\n--> 362                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    363 \n    364         # Flush output before sending the reply.\n    365         sys.stdout.flush()\n    366         sys.stderr.flush()\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'grid_search2.fit(np.array(data[\\'X\\']), data[\\...r\" % (param_name, best_parameters2[param_name]))', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Print object>, <_ast.Print object>, <_ast.Print object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-62-d7cb5029435f>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3001 \n   3002         try:\n   3003             for i, node in enumerate(to_run_exec):\n   3004                 mod = ast.Module([node])\n   3005                 code = compiler(mod, cell_name, \"exec\")\n-> 3006                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a14e2db0, file \"<ipython-input-62-d7cb5029435f>\", line 1>\n        self.user_global_ns = {'Business': <class 'foodbornenyc.models.businesses.Business'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Document': <class 'foodbornenyc.models.documents.Document'>, 'English': <class 'spacy.en.English'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"#from yelp classifier training notebook\\nfrom ...                           n_jobs=-1, verbose=1)\", u'from spacy.en import English\\nparser = English()', u'import foodbornenyc.models.models as models\\nf...rom foodbornenyc.models.metadata import metadata', u\"import xlrd\\nf = xlrd.open_workbook('data/yelp...sifier_data.xlsx')\\nsheet1 = f.sheet_by_index(0)\", u'from sklearn.externals import joblib\\nfrom foo... joblib.load(\"../\"+config[\\'model_file\\'])\\nsick', u'import numpy as np\\nfrom sklearn.metrics impor...t fp_rate / tp_rate\\n    print fn_rate / tn_rate', u'reviews = []\\nfor i, (rev, label) in enumerate...:rev.value, \"label\":label.value})\\nprint reviews', u'analyze(reviews, sick)', u'sheet2 = xlrd.open_workbook(\\'data/sick_test_p...rev.value, \"label\":label.value})\\nprint reviews2', u'analyze(reviews2, sick)', u'sick.steps', u'# key words to watch out for: poisoning, sick,..._, token.head, [t.orth_ for t in token.children]', u'def transform_doc_1(doc): \\n    #if root of se... \" \".join(out)\\n\\nprint transform_doc_1(example)', u'def transform_doc_2(doc): \\n    #if negation a... \" \".join(out)\\n\\nprint transform_doc_2(example)', u'from sklearn.base import TransformerMixin\\ncla...=None, **fit_params):\\n        return self\\n    ', u\"from sklearn.pipeline import Pipeline\\npipe = ...egationTransformer()), ('oldPipe', sick)])\\npipe\", u'analyze(reviews, pipe)', u'analyze(reviews2, pipe)', u\"#try refitting the pipeline?\\npipe1 = Pipeline...er', NegationTransformer()), ('oldPipe', sick)])\", ...], 'Location': <class 'foodbornenyc.models.locations.Location'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NegationTransformer': <class '__main__.NegationTransformer'>, ...}\n        self.user_ns = {'Business': <class 'foodbornenyc.models.businesses.Business'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Document': <class 'foodbornenyc.models.documents.Document'>, 'English': <class 'spacy.en.English'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"#from yelp classifier training notebook\\nfrom ...                           n_jobs=-1, verbose=1)\", u'from spacy.en import English\\nparser = English()', u'import foodbornenyc.models.models as models\\nf...rom foodbornenyc.models.metadata import metadata', u\"import xlrd\\nf = xlrd.open_workbook('data/yelp...sifier_data.xlsx')\\nsheet1 = f.sheet_by_index(0)\", u'from sklearn.externals import joblib\\nfrom foo... joblib.load(\"../\"+config[\\'model_file\\'])\\nsick', u'import numpy as np\\nfrom sklearn.metrics impor...t fp_rate / tp_rate\\n    print fn_rate / tn_rate', u'reviews = []\\nfor i, (rev, label) in enumerate...:rev.value, \"label\":label.value})\\nprint reviews', u'analyze(reviews, sick)', u'sheet2 = xlrd.open_workbook(\\'data/sick_test_p...rev.value, \"label\":label.value})\\nprint reviews2', u'analyze(reviews2, sick)', u'sick.steps', u'# key words to watch out for: poisoning, sick,..._, token.head, [t.orth_ for t in token.children]', u'def transform_doc_1(doc): \\n    #if root of se... \" \".join(out)\\n\\nprint transform_doc_1(example)', u'def transform_doc_2(doc): \\n    #if negation a... \" \".join(out)\\n\\nprint transform_doc_2(example)', u'from sklearn.base import TransformerMixin\\ncla...=None, **fit_params):\\n        return self\\n    ', u\"from sklearn.pipeline import Pipeline\\npipe = ...egationTransformer()), ('oldPipe', sick)])\\npipe\", u'analyze(reviews, pipe)', u'analyze(reviews2, pipe)', u\"#try refitting the pipeline?\\npipe1 = Pipeline...er', NegationTransformer()), ('oldPipe', sick)])\", ...], 'Location': <class 'foodbornenyc.models.locations.Location'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NegationTransformer': <class '__main__.NegationTransformer'>, ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/Users/kevinzeng/FoodborneNYC/notebooks/<ipython-input-62-d7cb5029435f> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 grid_search2.fit(np.array(data['X']), data['y'])\n      7 print()\n      8 \n      9 print(\"Best score: %0.3f\" % grid_search2.best_score_)\n     10 print(\"Best parameters set:\")\n     11 best_parameters2 = grid_search2.best_estimator_.get_params()\n     12 for param_name in sorted(param_grid.keys()):\n     13     print(\"\\t%s: %r\" % (param_name, best_parameters2[param_name]))\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...rer(my_roc_auc, needs_threshold=True), verbose=1), X=array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...])\n    799         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    800             Target relative to X for classification or regression;\n    801             None for unsupervised learning.\n    802 \n    803         \"\"\"\n--> 804         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method GridSearchCV._fit of GridSearchCV(...er(my_roc_auc, needs_threshold=True), verbose=1)>\n        X = array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952')\n        y = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...]\n        self.param_grid = {'count__ngram_range': [(1, 1), (1, 2), (1, 3)], 'logreg__C': [0.001, 0.01, 0.1], 'tfidf__norm': ['l1', 'l2'], 'tfidf__sublinear_tf': [True, False], 'tfidf__use_idf': [True, False]}\n    805 \n    806 \n    807 class RandomizedSearchCV(BaseSearchCV):\n    808     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...rer(my_roc_auc, needs_threshold=True), verbose=1), X=array([ u'My friends and I ordered 3 burgers and...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    548         )(\n    549             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    550                                     train, test, self.verbose, parameters,\n    551                                     self.fit_params, return_parameters=True,\n    552                                     error_score=self.error_score)\n--> 553                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    554                 for train, test in cv)\n    555 \n    556         # Out is a list of triplet: score, estimator, n_test_samples\n    557         n_fits = len(out)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu May  5 21:20:01 2016\nPID: 49031     Python 2.7.9: /Users/kevinzeng/.virtualenvs/fbnyc/bin/python\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], make_scorer(my_roc_auc, needs_threshold=True), array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), 1, {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], make_scorer(my_roc_auc, needs_threshold=True), array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), 1, {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), X=memmap([ u'My friends and I ordered 3 burgers an...#worldcup #Newyorkbars.'], \n      dtype='<U4952'), y=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...], scorer=make_scorer(my_roc_auc, needs_threshold=True), train=array([   0,    3,    6,    7,    8,   10,   11,...1383, 1384, 1386, 1388,\n       1389, 1390, 1391]), test=array([   1,    2,    4,    5,    9,   12,   14,...1373, 1376, 1378, 1379,\n       1380, 1385, 1387]), verbose=1, parameters={'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1515     fit_params = fit_params if fit_params is not None else {}\n   1516     fit_params = dict([(k, _index_param_value(X, v, train))\n   1517                       for k, v in fit_params.items()])\n   1518 \n   1519     if parameters is not None:\n-> 1520         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...     tol=0.0001, verbose=0, warm_start=False))])>\n        parameters = {'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True}\n   1521 \n   1522     start_time = time.time()\n   1523 \n   1524     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/kevinzeng/.virtualenvs/fbnyc/lib/python2.7/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))]), **params={'count__ngram_range': (1, 1), 'logreg__C': 0.001, 'tfidf__norm': 'l1', 'tfidf__sublinear_tf': True, 'tfidf__use_idf': True})\n    256                 name, sub_name = split\n    257                 if name not in valid_params:\n    258                     raise ValueError('Invalid parameter %s for estimator %s. '\n    259                                      'Check the list of available parameters '\n    260                                      'with `estimator.get_params().keys()`.' %\n--> 261                                      (name, self))\n        name = 'logreg'\n        self = Pipeline(steps=[('count', CountVectorizer(analyz...      tol=0.0001, verbose=0, warm_start=False))])\n    262                 sub_object = valid_params[name]\n    263                 sub_object.set_params(**{sub_name: value})\n    264             else:\n    265                 # simple objects case\n\nValueError: Invalid parameter logreg for estimator Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n        lowercase=True, max_df=0.95, max_features=None, min_df=1,\n        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n        ...alty='l2', random_state=57, solver='liblinear',\n          tol=0.0001, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "grid_search2.fit(np.array(data['X']), data['y'])\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search2.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters2 = grid_search2.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters2[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
